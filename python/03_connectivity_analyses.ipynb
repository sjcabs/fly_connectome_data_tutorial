{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 03: Connectivity Analyses\n",
    "\n",
    "**Author:** Alexander Bates  \n",
    "**Python Version**\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This tutorial demonstrates connectivity analysis using Python. We'll explore:\n",
    "\n",
    "- Loading and analyzing connectivity data (edgelists)\n",
    "- Computing network statistics\n",
    "- Creating connectivity matrices\n",
    "- UMAP dimensionality reduction\n",
    "- Network visualization with NetworkX and Plotly\n",
    "- Hierarchical clustering of connectivity patterns\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset configuration",
    "DATASET = \"banc_746\"",
    "DATASET_ID = \"banc_746_id\"",
    "",
    "# Data location",
    "DATA_PATH = \"gs://sjcabs_2025_data\"",
    "USE_GCS = DATA_PATH.startswith(\"gs://\")",
    "",
    "# Image output directory",
    "import os",
    "IMG_DIR = \"images/tutorial_03\"",
    "os.makedirs(IMG_DIR, exist_ok=True)",
    "",
    "print(f\"Dataset: {DATASET}\")",
    "print(f\"Data location: {DATA_PATH}\")",
    "print(f\"Images will be saved to: {IMG_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all common packages and helper functions\n",
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "from setup_helpers import *\n",
    "\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "print(f\"networkx version: {nx.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup GCS Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_GCS:\n",
    "    print(\"Setting up Google Cloud Storage access...\")\n",
    "    gcs = gcsfs.GCSFileSystem(token='google_default')\n",
    "    print(\"\u2713 GCS filesystem initialized\")\n",
    "else:\n",
    "    gcs = None\n",
    "    print(\"Using local filesystem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def construct_path(data_root, dataset, file_type=\"meta\"):\n    \"\"\"Construct file paths for dataset files.\"\"\"\n    dataset_name = dataset.split(\"_\")[0]\n    \n    # File type mappings with correct naming\n    file_mappings = {\n        \"meta\": f\"{dataset}_meta.feather\",\n        \"edgelist\": f\"{dataset}_edgelist.feather\",\n        \"edgelist_simple\": f\"{dataset}_simple_edgelist.feather\",  # Note: simple comes before edgelist\n        \"synapses\": f\"{dataset}_synapses.parquet\"\n    }\n    \n    if file_type not in file_mappings:\n        raise ValueError(f\"Unknown file_type: {file_type}\")\n    \n    filename = file_mappings[file_type]\n    full_path = f\"{data_root}/{dataset_name}/{filename}\"\n    \n    return full_path\n\n\ndef read_feather_gcs(path, gcs_fs=None):\n    \"\"\"Read Feather file from GCS or local path.\"\"\"\n    if path.startswith(\"gs://\"):\n        if gcs_fs is None:\n            raise ValueError(\"gcs_fs required for GCS paths\")\n        \n        print(f\"Reading from GCS: {path}\")\n        gcs_path = path.replace(\"gs://\", \"\")\n        \n        with gcs_fs.open(gcs_path, 'rb') as f:\n            df = feather.read_feather(f)\n        \n        print(f\"\u2713 Loaded {len(df):,} rows\")\n        return df\n    else:\n        print(f\"Reading from local path: {path}\")\n        df = pd.read_feather(path)\n        print(f\"\u2713 Loaded {len(df):,} rows\")\n        return df\n\n\nprint(\"\u2713 Helper functions defined\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "We'll load:\n",
    "1. **Metadata** - neuron annotations\n",
    "2. **Edgelist** - neuron-to-neuron connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct paths\n",
    "meta_path = construct_path(DATA_PATH, DATASET, \"meta\")\n",
    "edgelist_path = construct_path(DATA_PATH, DATASET, \"edgelist_simple\")\n",
    "\n",
    "print(\"File paths:\")\n",
    "print(f\"  Metadata: {meta_path}\")\n",
    "print(f\"  Edgelist: {edgelist_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = read_feather_gcs(meta_path, gcs_fs=gcs)\n",
    "\n",
    "print(f\"\\nTotal neurons: {len(meta):,}\")\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Edgelist (Connectivity Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgelist = read_feather_gcs(edgelist_path, gcs_fs=gcs)\n",
    "\n",
    "print(f\"\\nTotal connections: {len(edgelist):,}\")\n",
    "print(f\"Columns: {list(edgelist.columns)}\")\n",
    "edgelist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neurotransmitter Consensus\n",
    "\n",
    "Establish consensus neurotransmitter for each neuron based on prediction scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get neurotransmitter with highest score for each neuron\n",
    "meta['nt'] = meta['neurotransmitter_predicted']\n",
    "\n",
    "# Classify as excitatory or inhibitory\n",
    "excitatory_nts = ['acetylcholine', 'glutamate']\n",
    "inhibitory_nts = ['gaba', 'glycine']\n",
    "\n",
    "meta['nt_type'] = 'other'\n",
    "meta.loc[meta['nt'].isin(excitatory_nts), 'nt_type'] = 'excitatory'\n",
    "meta.loc[meta['nt'].isin(inhibitory_nts), 'nt_type'] = 'inhibitory'\n",
    "\n",
    "print(\"Neurotransmitter distribution:\")\n",
    "print(meta['nt'].value_counts())\n",
    "print(\"\\nNeurotransmitter type distribution:\")\n",
    "print(meta['nt_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Signed Connectivity\n",
    "\n",
    "Infer edge sign based on presynaptic neuron's neurotransmitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map neurotransmitter types to edges\n",
    "nt_map = dict(zip(meta[DATASET_ID], meta['nt_type']))\n",
    "edgelist['nt_type'] = edgelist['pre'].map(nt_map)\n",
    "\n",
    "# Assign sign: excitatory = +1, inhibitory = -1, other = 0\n",
    "edgelist['sign'] = 0\n",
    "edgelist.loc[edgelist['nt_type'] == 'excitatory', 'sign'] = 1\n",
    "edgelist.loc[edgelist['nt_type'] == 'inhibitory', 'sign'] = -1\n",
    "\n",
    "# Create signed weight\n",
    "edgelist['weight_signed'] = edgelist['weight'] * edgelist['sign']\n",
    "\n",
    "print(f\"\\n\u2713 Added signed connectivity\")\n",
    "print(f\"Excitatory edges: {(edgelist['sign'] == 1).sum():,}\")\n",
    "print(f\"Inhibitory edges: {(edgelist['sign'] == -1).sum():,}\")\n",
    "print(f\"Other edges: {(edgelist['sign'] == 0).sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Visualize Signed Weight Distribution\n\nLet's visualize the distribution of signed connection weights."
  },
  {
   "cell_type": "code",
   "source": "# Filter edges with non-zero sign for visualization\nedgelist_signed = edgelist[edgelist['sign'] != 0].copy()\n\n# Create histogram of signed weights\nfig = go.Figure()\n\nfig.add_trace(go.Histogram(\n    x=edgelist_signed[edgelist_signed['sign'] == 1]['weight'],\n    name='Excitatory',\n    marker_color='red',\n    opacity=0.7,\n    nbinsx=50\n))\n\nfig.add_trace(go.Histogram(\n    x=edgelist_signed[edgelist_signed['sign'] == -1]['weight'],\n    name='Inhibitory',\n    marker_color='blue',\n    opacity=0.7,\n    nbinsx=50\n))\n\nfig.update_layout(\n    title='Distribution of Signed Connection Weights',\n    xaxis_title='Connection Weight (synapse count)',\n    yaxis_title='Count',\n    barmode='overlay',\n    template='plotly_white',\n    height=500\n)\n\nfig.write_html(f\"{IMG_DIR}/{DATASET}_signed_weight_distribution.html\")\nfig.show()\n\nprint(f\"\u2713 Saved signed weight distribution plot\")\nprint(f\"Excitatory connections: {(edgelist['sign'] == 1).sum():,}\")\nprint(f\"Inhibitory connections: {(edgelist['sign'] == -1).sum():,}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Explore Neuron Classes\n\nLet's examine the distribution of neurons by super_class.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Count neurons by super_class\nsuper_class_counts = meta['super_class'].value_counts().reset_index()\nsuper_class_counts.columns = ['super_class', 'count']\n\n# Create bar plot\nfig = px.bar(\n    super_class_counts,\n    x='super_class',\n    y='count',\n    color='super_class',\n    title='Neuron Distribution by Super Class',\n    labels={'super_class': 'Super Class', 'count': 'Number of Neurons'},\n    template='plotly_white',\n    height=500\n)\n\nfig.update_layout(showlegend=False, xaxis_tickangle=-45)\nfig.write_html(f\"{IMG_DIR}/{DATASET}_super_class.html\")\nfig.show()\n\nprint(f\"\u2713 Saved super_class distribution plot\")\nprint(f\"\\nSuper class distribution:\")\nprint(super_class_counts)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Weight Correlation Analysis\n\nExamine the relationship between synapse count and normalized weight.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Flow Subclass Analysis\n\nExamine sensory and effector neurons by their cell sub-classes.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Get sensory and effector neurons\nflow_subset = meta[meta['flow'].isin(['afferent', 'efferent'])].copy()\n\nif len(flow_subset) > 0:\n    # Get top 15 cell sub-classes per flow type\n    flow_counts = flow_subset.groupby(['flow', 'cell_sub_class']).size().reset_index(name='count')\n    top_per_flow = flow_counts.sort_values(['flow', 'count'], ascending=[True, False])\n    top_per_flow = top_per_flow.groupby('flow').head(15)\n    \n    # Rename flow types for display\n    top_per_flow['flow_label'] = top_per_flow['flow'].map({\n        'afferent': 'Sensory (afferent)',\n        'efferent': 'Effector (efferent)'\n    })\n    \n    # Create faceted bar plot\n    fig = px.bar(\n        top_per_flow,\n        x='cell_sub_class',\n        y='count',\n        color='cell_sub_class',\n        facet_col='flow_label',\n        title='Top 15 Cell Sub-Classes per Flow Type',\n        labels={'cell_sub_class': 'Cell Sub-Class', 'count': 'Number of Neurons'},\n        template='plotly_white',\n        height=500\n    )\n    \n    fig.update_xaxes(tickangle=-45)\n    fig.update_layout(showlegend=False)\n    fig.write_html(f\"{IMG_DIR}/{DATASET}_flow_subclass.html\")\n    fig.show()\n    \n    print(f\"\u2713 Saved flow subclass plot\")\n    print(f\"Sensory neuron count: {(flow_subset['flow'] == 'afferent').sum():,}\")\n    print(f\"Effector neuron count: {(flow_subset['flow'] == 'efferent').sum():,}\")\nelse:\n    print(\"No sensory or effector neurons in this subset.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Sample if too many points\nif len(edgelist) > 50000:\n    edgelist_sample = edgelist.sample(n=50000, random_state=42)\n    print(f\"Sampling 50,000 connections for visualization\")\nelse:\n    edgelist_sample = edgelist\n\n# Calculate Spearman correlation\nfrom scipy.stats import spearmanr\ncorr, _ = spearmanr(edgelist['count'], edgelist['norm'])\n\n# Create scatter plot\nfig = px.scatter(\n    edgelist_sample,\n    x='count',\n    y='norm',\n    log_x=True,\n    log_y=True,\n    opacity=0.3,\n    title=f'Relationship between Synapse Count and Normalized Weight<br><sub>Spearman correlation: {corr:.3f}</sub>',\n    labels={'count': 'Synapse Count (log scale)', 'norm': 'Normalized Weight (log scale)'},\n    template='plotly_white',\n    height=500\n)\n\n# Add trendline\nfig.update_traces(marker=dict(color='steelblue', size=3))\n\nfig.write_html(f\"{IMG_DIR}/{DATASET}_weight_correlation.html\")\nfig.show()\n\nprint(f\"\u2713 Saved weight correlation plot\")\nprint(f\"Spearman correlation: {corr:.3f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Degree Distribution\n\nAnalyze in-degree and out-degree distributions with different synapse count thresholds.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Calculate in-degree and out-degree with two thresholds\ndegree_data = []\n\n# Threshold 1: count > 1\nin_degree_1 = edgelist[edgelist['count'] > 1].groupby('post').size().reset_index()\nin_degree_1.columns = ['neuron', 'degree']\nin_degree_1['type'] = 'In-degree'\nin_degree_1['threshold'] = '>1 synapse'\n\nout_degree_1 = edgelist[edgelist['count'] > 1].groupby('pre').size().reset_index()\nout_degree_1.columns = ['neuron', 'degree']\nout_degree_1['type'] = 'Out-degree'\nout_degree_1['threshold'] = '>1 synapse'\n\n# Threshold 2: count > 10\nin_degree_10 = edgelist[edgelist['count'] > 10].groupby('post').size().reset_index()\nin_degree_10.columns = ['neuron', 'degree']\nin_degree_10['type'] = 'In-degree'\nin_degree_10['threshold'] = '>10 synapses'\n\nout_degree_10 = edgelist[edgelist['count'] > 10].groupby('pre').size().reset_index()\nout_degree_10.columns = ['neuron', 'degree']\nout_degree_10['type'] = 'Out-degree'\nout_degree_10['threshold'] = '>10 synapses'\n\n# Combine all\ndegree_data = pd.concat([in_degree_1, out_degree_1, in_degree_10, out_degree_10], ignore_index=True)\n\n# Create density plot using histogram\nfig = make_subplots(rows=1, cols=2, subplot_titles=('>1 synapse', '>10 synapses'))\n\nfor i, threshold in enumerate(['>1 synapse', '>10 synapses']):\n    subset = degree_data[degree_data['threshold'] == threshold]\n    \n    for dtype, color in [('In-degree', 'orange'), ('Out-degree', 'blue')]:\n        data = subset[subset['type'] == dtype]['degree']\n        \n        fig.add_trace(\n            go.Histogram(\n                x=np.log10(data),\n                name=dtype,\n                marker_color=color,\n                opacity=0.6,\n                nbinsx=50,\n                histnorm='probability density',\n                showlegend=(i == 0)\n            ),\n            row=1, col=i+1\n        )\n\nfig.update_xaxes(title_text=\"Degree (log10 scale)\", row=1, col=1)\nfig.update_xaxes(title_text=\"Degree (log10 scale)\", row=1, col=2)\nfig.update_yaxes(title_text=\"Density\", row=1, col=1)\n\nfig.update_layout(\n    title_text='Degree Distribution by Synapse Count Threshold',\n    height=500,\n    template='plotly_white',\n    barmode='overlay'\n)\n\nfig.write_html(f\"{IMG_DIR}/{DATASET}_degree_distribution.html\")\nfig.show()\n\nprint(f\"\u2713 Saved degree distribution plot\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Connectivity Matrix by Cell Type\n\nCreate a connectivity matrix showing strong connections between cell types.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Add cell_class to edgelist\ncell_class_map = dict(zip(meta[DATASET_ID], meta['cell_class']))\nedgelist['pre_class'] = edgelist['pre'].map(cell_class_map)\nedgelist['post_class'] = edgelist['post'].map(cell_class_map)\n\n# Aggregate by cell_class (sum weights)\nclass_connectivity = edgelist.groupby(['pre_class', 'post_class'])['weight'].sum().reset_index()\n\n# Find most connected cell classes\ntop_classes_pre = class_connectivity.groupby('pre_class')['weight'].sum().nlargest(20).index\ntop_classes_post = class_connectivity.groupby('post_class')['weight'].sum().nlargest(20).index\ntop_classes = list(set(top_classes_pre) | set(top_classes_post))\n\n# Filter to top classes\nclass_conn_filtered = class_connectivity[\n    class_connectivity['pre_class'].isin(top_classes) &\n    class_connectivity['post_class'].isin(top_classes)\n]\n\n# Create pivot table for heatmap\nconn_matrix = class_conn_filtered.pivot(index='pre_class', columns='post_class', values='weight').fillna(0)\n\n# Create heatmap\nfig = go.Figure(data=go.Heatmap(\n    z=conn_matrix.values,\n    x=conn_matrix.columns,\n    y=conn_matrix.index,\n    colorscale='Viridis',\n    colorbar=dict(title='Total Weight')\n))\n\nfig.update_layout(\n    title=f'Connectivity Matrix: Top {len(top_classes)} Cell Classes',\n    xaxis_title='Postsynaptic Cell Class',\n    yaxis_title='Presynaptic Cell Class',\n    height=800,\n    width=900,\n    template='plotly_white'\n)\n\nfig.update_xaxes(tickangle=-45)\n\nfig.write_html(f\"{IMG_DIR}/{DATASET}_connectivity_matrix.html\")\nfig.show()\n\nprint(f\"\u2713 Saved connectivity matrix heatmap\")\nprint(f\"Matrix dimensions: {conn_matrix.shape}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensory and Effector Connectivity Heatmaps\n",
    "\n",
    "Let's examine connectivity patterns for sensory (afferent) and effector (efferent) neurons.\n",
    "\n",
    "For these neurons, we'll use `cell_class` labels instead of `cell_type` for better interpretability."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create edgelist with mixed labels (cell_class for sensory/effector, cell_type for others)\n",
    "# Add flow information to edgelist\n",
    "flow_map = dict(zip(meta[DATASET_ID], meta['flow']))\n",
    "edgelist['pre_flow'] = edgelist['pre'].map(flow_map)\n",
    "edgelist['post_flow'] = edgelist['post'].map(flow_map)\n",
    "\n",
    "# Create labels: use cell_class for sensory/effector, cell_type for others\n",
    "def get_label(row, side='pre'):\n",
    "    neuron_id = row[side]\n",
    "    flow = row[f'{side}_flow']\n",
    "    \n",
    "    if pd.isna(neuron_id):\n",
    "        return None\n",
    "    \n",
    "    neuron_meta = meta[meta[DATASET_ID] == neuron_id]\n",
    "    if len(neuron_meta) == 0:\n",
    "        return None\n",
    "    \n",
    "    if flow in ['afferent', 'efferent'] and not pd.isna(neuron_meta['cell_class'].iloc[0]):\n",
    "        return neuron_meta['cell_class'].iloc[0]\n",
    "    else:\n",
    "        return neuron_meta['cell_type'].iloc[0]\n",
    "\n",
    "print(\"Creating mixed labels for edgelist...\")\n",
    "edgelist['pre_label'] = edgelist.apply(lambda row: get_label(row, 'pre'), axis=1)\n",
    "edgelist['post_label'] = edgelist.apply(lambda row: get_label(row, 'post'), axis=1)\n",
    "\n",
    "# Filter out rows with missing labels\n",
    "edgelist_mixed = edgelist[edgelist['pre_label'].notna() & edgelist['post_label'].notna()].copy()\n",
    "\n",
    "print(f\"\\u2713 Created mixed labels edgelist with {len(edgelist_mixed):,} connections\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensory Neuron Outputs\n",
    "\n",
    "Which cell types receive strong input from sensory neurons (\u2265100 synapses)?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate total inputs per target from sensory neurons\n",
    "sensory_post_totals = edgelist_mixed[edgelist_mixed['pre_flow'] == 'afferent'].groupby('post_label')['count'].sum()\n",
    "\n",
    "# Get sensory outputs (\u2265100 synapses)\n",
    "sensory_outputs = edgelist_mixed[edgelist_mixed['pre_flow'] == 'afferent'].groupby(\n",
    "    ['pre_label', 'post_label']\n",
    ")['count'].sum().reset_index()\n",
    "sensory_outputs.columns = ['pre_label', 'post_label', 'total_count']\n",
    "\n",
    "# Add total counts and normalize\n",
    "sensory_outputs = sensory_outputs.merge(\n",
    "    sensory_post_totals.rename('post_total_count'),\n",
    "    left_on='post_label',\n",
    "    right_index=True\n",
    ")\n",
    "sensory_outputs['norm'] = sensory_outputs['total_count'] / sensory_outputs['post_total_count']\n",
    "\n",
    "# Filter to \u2265100 synapses\n",
    "sensory_outputs = sensory_outputs[sensory_outputs['total_count'] >= 100]\n",
    "\n",
    "if len(sensory_outputs) > 0:\n",
    "    print(f\"Found {len(sensory_outputs)} sensory connections \u2265100 synapses\")\n",
    "    print(f\"Sensory neuron types: {sensory_outputs['pre_label'].nunique()}\")\n",
    "    print(f\"Target neuron types: {sensory_outputs['post_label'].nunique()}\")\n",
    "    \n",
    "    # Create matrix for heatmap\n",
    "    sensory_matrix = sensory_outputs.pivot(\n",
    "        index='pre_label',\n",
    "        columns='post_label',\n",
    "        values='norm'\n",
    "    ).fillna(0)\n",
    "    \n",
    "    print(f\"Matrix dimensions: {sensory_matrix.shape[0]} x {sensory_matrix.shape[1]}\")\n",
    "    \n",
    "    # Perform hierarchical clustering for ordering\n",
    "    from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "    from scipy.spatial.distance import pdist\n",
    "    \n",
    "    # Cluster rows and columns\n",
    "    if sensory_matrix.shape[0] > 1:\n",
    "        row_linkage = linkage(pdist(sensory_matrix.values, metric='euclidean'), method='ward')\n",
    "        row_order = dendrogram(row_linkage, no_plot=True)['leaves']\n",
    "    else:\n",
    "        row_order = [0]\n",
    "    \n",
    "    if sensory_matrix.shape[1] > 1:\n",
    "        col_linkage = linkage(pdist(sensory_matrix.T.values, metric='euclidean'), method='ward')\n",
    "        col_order = dendrogram(col_linkage, no_plot=True)['leaves']\n",
    "    else:\n",
    "        col_order = [0]\n",
    "    \n",
    "    # Reorder matrix\n",
    "    sensory_matrix_ordered = sensory_matrix.iloc[row_order, col_order]\n",
    "    \n",
    "    # Create static heatmap with matplotlib/seaborn\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    sns.heatmap(\n",
    "        sensory_matrix_ordered,\n",
    "        cmap='RdYlBu_r',  # Cold to hot\n",
    "        xticklabels=False,\n",
    "        yticklabels=False,\n",
    "        cbar_kws={'label': 'Normalized Weight'},\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title('Sensory Neuron Outputs (\u2265100 synapses)', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Target Neuron Type', fontsize=12)\n",
    "    ax.set_ylabel('Sensory Neuron Type', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{IMG_DIR}/{DATASET}_sensory_outputs.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"\\u2713 Saved static heatmap: {IMG_DIR}/{DATASET}_sensory_outputs.png\")\n",
    "    \n",
    "    # Create interactive heatmap with plotly\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=sensory_matrix_ordered.values,\n",
    "        x=sensory_matrix_ordered.columns,\n",
    "        y=sensory_matrix_ordered.index,\n",
    "        colorscale=[\n",
    "            [0, 'rgb(0,0,128)'],      # navy\n",
    "            [0.2, 'rgb(0,0,255)'],    # blue\n",
    "            [0.4, 'rgb(0,255,255)'],  # cyan\n",
    "            [0.6, 'rgb(255,255,0)'],  # yellow\n",
    "            [0.8, 'rgb(255,165,0)'],  # orange\n",
    "            [1, 'rgb(255,0,0)']       # red\n",
    "        ],\n",
    "        colorbar=dict(title='Normalized<br>Weight'),\n",
    "        hovertemplate='Sensory: %{y}<br>Target: %{x}<br>Weight: %{z:.3f}<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Sensory Neuron Outputs (\u2265100 synapses)',\n",
    "        xaxis_title='Target Neuron Type',\n",
    "        yaxis_title='Sensory Neuron Type',\n",
    "        xaxis=dict(showticklabels=False),\n",
    "        yaxis=dict(showticklabels=False),\n",
    "        height=800,\n",
    "        width=900,\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    print(f\"\\u2713 Displayed interactive heatmap\")\n",
    "else:\n",
    "    print(\"No sensory neurons with \u2265100 synapses found in this dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effector Neuron Inputs\n",
    "\n",
    "Which cell types provide strong input to effector neurons (\u2265100 synapses)?\n",
    "\n",
    "We'll use signed weights here to show excitatory (+) vs inhibitory (-) connections."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate total inputs per effector neuron type\n",
    "effector_post_totals = edgelist_mixed[edgelist_mixed['post_flow'] == 'efferent'].groupby('post_label')['count'].sum()\n",
    "\n",
    "# Get effector inputs (\u2265100 synapses) with signed weights\n",
    "effector_inputs = edgelist_mixed[edgelist_mixed['post_flow'] == 'efferent'].groupby(\n",
    "    ['pre_label', 'post_label']\n",
    ").agg({\n",
    "    'count': 'sum',\n",
    "    'weight_signed': 'sum'\n",
    "}).reset_index()\n",
    "effector_inputs.columns = ['pre_label', 'post_label', 'total_count', 'total_signed_count']\n",
    "\n",
    "# Add total counts and normalize (signed)\n",
    "effector_inputs = effector_inputs.merge(\n",
    "    effector_post_totals.rename('post_total_count'),\n",
    "    left_on='post_label',\n",
    "    right_index=True\n",
    ")\n",
    "effector_inputs['signed_norm'] = effector_inputs['total_signed_count'] / effector_inputs['post_total_count']\n",
    "\n",
    "# Filter to \u2265100 synapses\n",
    "effector_inputs = effector_inputs[effector_inputs['total_count'] >= 100]\n",
    "\n",
    "if len(effector_inputs) > 0:\n",
    "    print(f\"Found {len(effector_inputs)} effector input connections \u2265100 synapses\")\n",
    "    print(f\"Input neuron types: {effector_inputs['pre_label'].nunique()}\")\n",
    "    print(f\"Effector neuron types: {effector_inputs['post_label'].nunique()}\")\n",
    "    \n",
    "    # Create matrix for heatmap\n",
    "    effector_matrix = effector_inputs.pivot(\n",
    "        index='pre_label',\n",
    "        columns='post_label',\n",
    "        values='signed_norm'\n",
    "    ).fillna(0)\n",
    "    \n",
    "    print(f\"Matrix dimensions: {effector_matrix.shape[0]} x {effector_matrix.shape[1]}\")\n",
    "    \n",
    "    # Perform hierarchical clustering on absolute values for ordering\n",
    "    if effector_matrix.shape[0] > 1:\n",
    "        row_linkage = linkage(pdist(np.abs(effector_matrix.values), metric='euclidean'), method='ward')\n",
    "        row_order = dendrogram(row_linkage, no_plot=True)['leaves']\n",
    "    else:\n",
    "        row_order = [0]\n",
    "    \n",
    "    if effector_matrix.shape[1] > 1:\n",
    "        col_linkage = linkage(pdist(np.abs(effector_matrix.T.values), metric='euclidean'), method='ward')\n",
    "        col_order = dendrogram(col_linkage, no_plot=True)['leaves']\n",
    "    else:\n",
    "        col_order = [0]\n",
    "    \n",
    "    # Reorder matrix\n",
    "    effector_matrix_ordered = effector_matrix.iloc[row_order, col_order]\n",
    "    \n",
    "    # Cap color scale for better visibility (use 25th and 75th percentiles)\n",
    "    p25 = np.percentile(effector_matrix_ordered.values, 25)\n",
    "    p75 = np.percentile(effector_matrix_ordered.values, 75)\n",
    "    max_abs_val = max(abs(p25), abs(p75))\n",
    "    \n",
    "    # Create static heatmap with matplotlib/seaborn (diverging colormap)\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    sns.heatmap(\n",
    "        effector_matrix_ordered,\n",
    "        cmap='RdBu_r',  # Diverging: red (positive/excitatory) to blue (negative/inhibitory)\n",
    "        center=0,\n",
    "        vmin=-max_abs_val,\n",
    "        vmax=max_abs_val,\n",
    "        xticklabels=False,\n",
    "        yticklabels=False,\n",
    "        cbar_kws={'label': 'Signed Weight'},\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title('Signed Effector Neuron Inputs (\u2265100 synapses)', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Effector Neuron Type', fontsize=12)\n",
    "    ax.set_ylabel('Input Neuron Type', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{IMG_DIR}/{DATASET}_effector_inputs.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"\\u2713 Saved static heatmap: {IMG_DIR}/{DATASET}_effector_inputs.png\")\n",
    "    \n",
    "    # Create interactive heatmap with plotly (diverging colormap)\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=effector_matrix_ordered.values,\n",
    "        x=effector_matrix_ordered.columns,\n",
    "        y=effector_matrix_ordered.index,\n",
    "        colorscale=[\n",
    "            [0, 'rgb(0,0,255)'],      # blue (inhibitory)\n",
    "            [0.25, 'rgb(0,255,255)'], # cyan\n",
    "            [0.5, 'rgb(255,255,255)'],# white (neutral)\n",
    "            [0.75, 'rgb(255,255,0)'], # yellow\n",
    "            [1, 'rgb(255,0,0)']       # red (excitatory)\n",
    "        ],\n",
    "        zmid=0,\n",
    "        zmin=-max_abs_val,\n",
    "        zmax=max_abs_val,\n",
    "        colorbar=dict(title='Signed<br>Weight'),\n",
    "        hovertemplate='Input: %{y}<br>Effector: %{x}<br>Weight: %{z:.3f}<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Signed Effector Neuron Inputs (\u2265100 synapses)',\n",
    "        xaxis_title='Effector Neuron Type',\n",
    "        yaxis_title='Input Neuron Type',\n",
    "        xaxis=dict(showticklabels=False),\n",
    "        yaxis=dict(showticklabels=False),\n",
    "        height=800,\n",
    "        width=900,\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    print(f\"\\u2713 Displayed interactive heatmap\")\n",
    "else:\n",
    "    print(\"No effector neurons with \u2265100 input synapses found in this dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## UMAP Dimensionality Reduction\n\nUse UMAP to visualize connectivity patterns in 2D space.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Filter neurons with sufficient connectivity (>=10 connections)\nconn_counts = pd.concat([\n    edgelist.groupby('pre').size().rename('n_out'),\n    edgelist.groupby('post').size().rename('n_in')\n], axis=1).fillna(0)\nconn_counts['total'] = conn_counts['n_out'] + conn_counts['n_in']\n\nneurons_to_use = conn_counts[conn_counts['total'] >= 10].index.tolist()\nprint(f\"Using {len(neurons_to_use):,} neurons with \u226510 connections\")\n\n# Create input/output connectivity matrix\n# Each neuron has both input and output partners\nedgelist_filtered = edgelist[\n    (edgelist['pre'].isin(neurons_to_use)) | \n    (edgelist['post'].isin(neurons_to_use))\n].copy()\n\n# Replace zeros with small value\nedgelist_filtered['norm'] = edgelist_filtered['norm'].replace(0, 0.001)\n\n# Prepare connectivity data (inputs and outputs as separate features)\nconn_list = []\n\n# Outputs: neuron -> partner\noutputs = edgelist_filtered[edgelist_filtered['pre'].isin(neurons_to_use)][['pre', 'post', 'norm']].copy()\noutputs.columns = ['neuron', 'partner', 'weight']\noutputs['partner'] = 'output_' + outputs['partner']\nconn_list.append(outputs)\n\n# Inputs: partner -> neuron\ninputs = edgelist_filtered[edgelist_filtered['post'].isin(neurons_to_use)][['post', 'pre', 'norm']].copy()\ninputs.columns = ['neuron', 'partner', 'weight']\ninputs['partner'] = 'input_' + inputs['partner']\nconn_list.append(inputs)\n\n# Combine\nconn_data = pd.concat(conn_list, ignore_index=True)\n\n# Create sparse matrix\nfrom scipy.sparse import csr_matrix\n\n# Create indices\nneuron_idx = {n: i for i, n in enumerate(neurons_to_use)}\npartner_idx = {p: i for i, p in enumerate(conn_data['partner'].unique())}\n\nrows = conn_data['neuron'].map(neuron_idx).values\ncols = conn_data['partner'].map(partner_idx).values\ndata = conn_data['weight'].values\n\nconnectivity_matrix = csr_matrix(\n    (data, (rows, cols)),\n    shape=(len(neurons_to_use), len(partner_idx))\n)\n\nprint(f\"Connectivity matrix: {connectivity_matrix.shape}\")\nprint(f\"Sparsity: {100 * (1 - connectivity_matrix.nnz / (connectivity_matrix.shape[0] * connectivity_matrix.shape[1])):.2f}%\")\n\n# Calculate cosine similarity\nprint(\"Calculating cosine similarity...\")\nfrom sklearn.metrics.pairwise import cosine_similarity\nsimilarity_matrix = cosine_similarity(connectivity_matrix)\nsimilarity_matrix[np.isnan(similarity_matrix)] = 0\nsimilarity_matrix[np.isinf(similarity_matrix)] = 0\n\nprint(f\"\u2713 Similarity matrix: {similarity_matrix.shape}\")\n\n# Convert to distance for UMAP\ndistance_matrix = 1 - similarity_matrix\ndistance_matrix = np.clip(distance_matrix, 0, 2)  # Ensure valid distances\n\n# Run UMAP\nprint(\"Running UMAP...\")\nreducer = umap.UMAP(\n    n_neighbors=15,\n    min_dist=0.1,\n    n_components=2,\n    metric='precomputed',\n    random_state=42\n)\n\numap_embedding = reducer.fit_transform(distance_matrix)\nprint(f\"\u2713 UMAP complete\")\n\n# Create DataFrame with UMAP coordinates and metadata\numap_df = pd.DataFrame({\n    'neuron_id': neurons_to_use,\n    'UMAP1': umap_embedding[:, 0],\n    'UMAP2': umap_embedding[:, 1]\n})\n\n# Add metadata\nmeta_subset = meta.set_index(DATASET_ID).loc[neurons_to_use]\numap_df = umap_df.merge(\n    meta_subset[['cell_type', 'super_class', 'cell_class', 'flow']].reset_index(),\n    left_on='neuron_id',\n    right_on=DATASET_ID,\n    how='left'\n)\n\nprint(f\"\u2713 Created UMAP DataFrame with {len(umap_df):,} neurons\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Visualize UMAP by Super Class",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Plot UMAP colored by super_class\nfig = px.scatter(\n    umap_df,\n    x='UMAP1',\n    y='UMAP2',\n    color='super_class',\n    hover_data=['neuron_id', 'cell_type'],\n    title='UMAP of Connectivity Patterns<br><sub>Colored by Super Class</sub>',\n    template='plotly_white',\n    height=600,\n    width=800\n)\n\nfig.update_traces(marker=dict(size=4, opacity=0.6))\nfig.write_html(f\"{IMG_DIR}/{DATASET}_umap_super_class.html\")\nfig.show()\n\nprint(f\"\u2713 Saved UMAP super_class plot\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Hierarchical Clustering\n\nCluster neurons based on their connectivity patterns.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Perform hierarchical clustering\nprint(\"Performing hierarchical clustering...\")\n\n# Use distance matrix\ncondensed_distance = squareform(distance_matrix, checks=False)\n\n# Hierarchical clustering\nlinkage_matrix = linkage(condensed_distance, method='ward')\n\n# Cut tree to get clusters (e.g., 12 clusters)\nn_clusters = 12\nclusters = cut_tree(linkage_matrix, n_clusters=n_clusters).flatten()\n\numap_df['cluster'] = clusters + 1  # 1-indexed for readability\n\nprint(f\"\u2713 Created {n_clusters} clusters\")\nprint(f\"\\nCluster sizes:\")\nprint(umap_df['cluster'].value_counts().sort_index())",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Visualize UMAP by Cluster",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Calculate cluster centroids for labeling\ncluster_centroids = umap_df.groupby('cluster').agg({\n    'UMAP1': 'mean',\n    'UMAP2': 'mean'\n}).reset_index()\n\n# Create color palette\nimport plotly.colors as pc\ncluster_colors = pc.sample_colorscale('Rainbow', [i/(n_clusters-1) for i in range(n_clusters)])\n\n# Plot UMAP colored by cluster\nfig = px.scatter(\n    umap_df,\n    x='UMAP1',\n    y='UMAP2',\n    color='cluster',\n    hover_data=['neuron_id', 'cell_type'],\n    title=f'Connectivity-Based Clusters<br><sub>{n_clusters} clusters identified by hierarchical clustering</sub>',\n    template='plotly_white',\n    height=600,\n    width=800,\n    color_continuous_scale='Rainbow'\n)\n\nfig.update_traces(marker=dict(size=5, opacity=0.7))\n\n# Add cluster labels\nfor _, row in cluster_centroids.iterrows():\n    fig.add_annotation(\n        x=row['UMAP1'],\n        y=row['UMAP2'],\n        text=str(int(row['cluster'])),\n        showarrow=False,\n        font=dict(size=14, color='black'),\n        bgcolor='white',\n        opacity=0.8\n    )\n\nfig.write_html(f\"{IMG_DIR}/{DATASET}_umap_clusters.html\")\nfig.show()\n\nprint(f\"\u2713 Saved UMAP clusters plot\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Cluster Composition Analysis\n\nExamine what cell types are present in each cluster.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Count super_classes within each cluster\ncluster_composition = umap_df.groupby(['cluster', 'super_class']).size().reset_index(name='count')\n\n# Get top 5 super_classes per cluster\ntop_per_cluster = cluster_composition.sort_values(['cluster', 'count'], ascending=[True, False])\ntop_per_cluster = top_per_cluster.groupby('cluster').head(5)\n\n# Create stacked bar chart\nfig = px.bar(\n    top_per_cluster,\n    x='cluster',\n    y='count',\n    color='super_class',\n    title='Cluster Composition by Super Class<br><sub>Top 5 super classes per cluster</sub>',\n    labels={'cluster': 'Cluster', 'count': 'Number of Neurons'},\n    template='plotly_white',\n    height=500,\n    width=900\n)\n\nfig.write_html(f\"{IMG_DIR}/{DATASET}_cluster_composition.html\")\nfig.show()\n\nprint(f\"\u2713 Saved cluster composition plot\")\n\n# Print detailed composition for first 3 clusters\nprint(\"\\nDetailed composition for clusters 1-3:\")\nfor cluster_id in range(1, 4):\n    cluster_data = cluster_composition[cluster_composition['cluster'] == cluster_id].sort_values('count', ascending=False)\n    print(f\"\\nCluster {cluster_id}:\")\n    print(cluster_data.head(5).to_string(index=False))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Sensory and Effector Neurons\n\nHighlight sensory (afferent) and effector (efferent) neurons in the UMAP space.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Identify sensory and effector neurons\numap_df['is_sensory'] = umap_df['flow'] == 'afferent'\numap_df['is_effector'] = umap_df['flow'] == 'efferent'\n\n# Create display categories\numap_df['neuron_type'] = 'Other'\numap_df.loc[umap_df['is_sensory'], 'neuron_type'] = 'Sensory (afferent)'\numap_df.loc[umap_df['is_effector'], 'neuron_type'] = 'Effector (efferent)'\n\n# Create plot with three layers\nfig = go.Figure()\n\n# Plot \"Other\" neurons first (grey, low opacity)\nother_df = umap_df[umap_df['neuron_type'] == 'Other']\nfig.add_trace(go.Scatter(\n    x=other_df['UMAP1'],\n    y=other_df['UMAP2'],\n    mode='markers',\n    name='Other',\n    marker=dict(color='grey', size=4, opacity=0.3),\n    hovertext=other_df['cell_type'],\n    hoverinfo='text'\n))\n\n# Plot sensory neurons (circles)\nsensory_df = umap_df[umap_df['is_sensory']]\nif len(sensory_df) > 0:\n    fig.add_trace(go.Scatter(\n        x=sensory_df['UMAP1'],\n        y=sensory_df['UMAP2'],\n        mode='markers',\n        name='Sensory (afferent)',\n        marker=dict(color='red', size=6, opacity=0.8, symbol='circle'),\n        hovertext=sensory_df['cell_type'],\n        hoverinfo='text'\n    ))\n\n# Plot effector neurons (squares)\neffector_df = umap_df[umap_df['is_effector']]\nif len(effector_df) > 0:\n    fig.add_trace(go.Scatter(\n        x=effector_df['UMAP1'],\n        y=effector_df['UMAP2'],\n        mode='markers',\n        name='Effector (efferent)',\n        marker=dict(color='blue', size=6, opacity=0.8, symbol='square'),\n        hovertext=effector_df['cell_type'],\n        hoverinfo='text'\n    ))\n\nfig.update_layout(\n    title='UMAP: Sensory and Effector Neurons<br><sub>Sensory = red circles, Effector = blue squares</sub>',\n    xaxis_title='UMAP1',\n    yaxis_title='UMAP2',\n    template='plotly_white',\n    height=600,\n    width=800\n)\n\nfig.write_html(f\"{IMG_DIR}/{DATASET}_umap_sensory_effector.html\")\nfig.show()\n\nprint(f\"\u2713 Saved sensory/effector UMAP plot\")\nprint(f\"Sensory neurons: {umap_df['is_sensory'].sum():,}\")\nprint(f\"Effector neurons: {umap_df['is_effector'].sum():,}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Summary\n\nIn this tutorial, we explored connectivity analysis methods for the {DATASET} dataset:\n\n### Key Analyses Performed:\n\n1. **Signed Connectivity** - Classified connections as excitatory/inhibitory based on neurotransmitter\n2. **Network Statistics** - Examined degree distributions and weight correlations\n3. **Connectivity Matrices** - Visualized strong connections between cell types\n4. **UMAP Dimensionality Reduction** - Projected high-dimensional connectivity patterns into 2D space\n5. **Hierarchical Clustering** - Grouped neurons by connectivity similarity\n6. **Functional Classes** - Identified sensory (afferent) and effector (efferent) neurons\n\n### Files Generated:\n\nAll plots have been saved to `{IMG_DIR}/` as interactive HTML files:\n- Signed weight distribution\n- Super class distribution  \n- Weight correlation analysis\n- Degree distributions\n- Connectivity matrix heatmap\n- UMAP visualizations (by super_class, by cluster, sensory/effector)\n- Cluster composition analysis\n\n### Next Steps:\n\n- Compare connectivity patterns across different datasets (FAFB, MANC, etc.)\n- Analyze specific pathways or circuits of interest\n- Investigate connection specificity and motifs\n- Combine morphological and connectivity features\n\n---\n\n**Tutorial Complete!** \n\nYou now have a comprehensive pipeline for analyzing fly connectome data in Python.",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}