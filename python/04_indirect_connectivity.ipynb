{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 04: Indirect Connectivity and Influence\n",
    "\n",
    "**Author:** Alexander Bates  \n",
    "**Date:** 2025-12-15\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This tutorial introduces the **influence metric**, a measure of indirect connectivity developed and used in the [BANC paper](https://www.biorxiv.org/content/10.1101/2024.12.28.630584v1) (Eckstein et al., 2025).\n",
    "\n",
    "### What is Influence?\n",
    "\n",
    "While direct synaptic connections tell us which neurons are connected, they don't capture the full picture of how signals propagate through neural circuits. The influence metric quantifies how strongly a neuron or group of neurons can affect downstream targets through both direct and indirect pathways.\n",
    "\n",
    "### How It Works\n",
    "\n",
    "The InfluenceCalculator package implements a linear dynamical model of neural signal propagation:\n",
    "\n",
    "**Model equation:** τ dr(t)/dt = (W - I)r(t) + s(t)\n",
    "\n",
    "Where:\n",
    "- **r(t)** = neural activity vector\n",
    "- **W** = connectivity matrix (scaled by synapse counts)\n",
    "- **s(t)** = stimulation input to seed neurons\n",
    "- **τ** = time constant\n",
    "\n",
    "At steady state, the influence score equals:\n",
    "\n",
    "**r∞ = -(W̃ - I)⁻¹s**\n",
    "\n",
    "Where W̃ is rescaled to ensure network stability. Results are log-transformed with a constant (+24) to produce \"adjusted influence\" scores above zero.\n",
    "\n",
    "### Key Advantages\n",
    "\n",
    "1. **Captures indirect effects**: Quantifies multi-synaptic pathways\n",
    "2. **Accounts for network structure**: Considers convergent and divergent connections\n",
    "3. **Computationally efficient**: Uses sparse matrix decomposition with caching for repeated calculations\n",
    "4. **Biologically validated**: Correlates with optogenetic activation experiments\n",
    "\n",
    "**Currently working with dataset:** banc_746"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import required packages\nimport pandas as pd\nimport numpy as np\nimport pyarrow.feather as feather\nimport gcsfs\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport umap\nfrom scipy.cluster.hierarchy import linkage, dendrogram\nfrom InfluenceCalculator import InfluenceCalculator\nfrom joblib import Parallel, delayed\nimport multiprocessing\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set up parallelization\nn_cores = max(1, multiprocessing.cpu_count() - 1)\nprint(f\"✓ All packages imported successfully\")\nprint(f\"Using {n_cores} cores for parallel processing\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration",
    "DATASET = \"banc_746\"",
    "DATASET_ID = \"banc_746_id\"",
    "DATA_PATH = \"gs://sjcabs_2025_data\"",
    "USE_GCS = DATA_PATH.startswith(\"gs://\")",
    "",
    "# Setup image output directory",
    "import os",
    "IMG_DIR = \"images/tutorial_04\"",
    "os.makedirs(IMG_DIR, exist_ok=True)",
    "",
    "print(f\"Working with dataset: {DATASET}\")",
    "print(f\"Data location: {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def construct_path(data_root, dataset, file_type=\"meta\"):\n",
    "    \"\"\"Construct file paths for dataset files.\"\"\"\n",
    "    dataset_name = dataset.split(\"_\")[0]\n",
    "    \n",
    "    file_mappings = {\n",
    "        \"meta\": f\"{dataset}_meta.feather\",\n",
    "        \"edgelist\": f\"{dataset}_edgelist.feather\",\n",
    "        \"edgelist_simple\": f\"{dataset}_simple_edgelist.feather\",\n",
    "        \"synapses\": f\"{dataset}_synapses.parquet\"\n",
    "    }\n",
    "    \n",
    "    if file_type not in file_mappings:\n",
    "        raise ValueError(f\"Unknown file_type: {file_type}\")\n",
    "    \n",
    "    filename = file_mappings[file_type]\n",
    "    full_path = f\"{data_root}/{dataset_name}/{filename}\"\n",
    "    \n",
    "    return full_path\n",
    "\n",
    "def read_feather_gcs(path, gcs_fs=None):\n",
    "    \"\"\"Read Feather file from GCS or local path.\"\"\"\n",
    "    if path.startswith(\"gs://\"):\n",
    "        if gcs_fs is None:\n",
    "            raise ValueError(\"gcs_fs required for GCS paths\")\n",
    "        \n",
    "        print(f\"Reading from GCS: {path}\")\n",
    "        gcs_path = path.replace(\"gs://\", \"\")\n",
    "        \n",
    "        with gcs_fs.open(gcs_path, 'rb') as f:\n",
    "            df = feather.read_feather(f)\n",
    "        \n",
    "        print(f\"✓ Loaded {len(df):,} rows\")\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"Reading from local path: {path}\")\n",
    "        df = pd.read_feather(path)\n",
    "        print(f\"✓ Loaded {len(df):,} rows\")\n",
    "        return df\n",
    "\n",
    "print(\"✓ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup GCS access if needed\n",
    "if USE_GCS:\n",
    "    print(\"Setting up Google Cloud Storage access...\")\n",
    "    gcs = gcsfs.GCSFileSystem(token='google_default')\n",
    "    print(\"✓ GCS filesystem initialized\")\n",
    "else:\n",
    "    gcs = None\n",
    "    print(\"Using local filesystem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "meta_path = construct_path(DATA_PATH, DATASET, \"meta\")\n",
    "print(f\"Loading metadata from: {meta_path}\")\n",
    "meta = read_feather_gcs(meta_path, gcs_fs=gcs)\n",
    "print(f\"✓ Loaded {len(meta):,} neurons\")\n",
    "print(f\"\\nMetadata columns: {list(meta.columns)}\")\n",
    "meta.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load edgelist\n",
    "edgelist_path = construct_path(DATA_PATH, DATASET, \"edgelist_simple\")\n",
    "print(f\"Loading edgelist from: {edgelist_path}\")\n",
    "edgelist_simple = read_feather_gcs(edgelist_path, gcs_fs=gcs)\n",
    "print(f\"✓ Loaded {len(edgelist_simple):,} connections\")\n",
    "print(f\"\\nEdgelist columns: {list(edgelist_simple.columns)}\")\n",
    "edgelist_simple.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Strong Connections\n",
    "\n",
    "To speed up influence calculations, we filter out weak connections (fewer than 5 synapses):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for connections with at least 5 synapses\n",
    "edgelist_filtered = edgelist_simple[edgelist_simple['count'] >= 5].copy()\n",
    "\n",
    "print(f\"Original connections: {len(edgelist_simple):,}\")\n",
    "print(f\"After filtering (≥5 synapses): {len(edgelist_filtered):,}\")\n",
    "print(f\"Retained: {100 * len(edgelist_filtered) / len(edgelist_simple):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Sensory Influence on Dopaminergic Neurons\n",
    "\n",
    "Let's examine how sensory neurons influence mushroom body dopaminergic neurons. This is biologically relevant because:\n",
    "\n",
    "- Dopaminergic neurons provide **teaching signals** for associative memory\n",
    "- They are hypothesised to receive unconditioned sensory information\n",
    "- **PAM** dopamine neurons are involved in appetitive (reward) learning\n",
    "- **PPL1** dopamine neurons are involved in aversive (punishment) learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Source and Target Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: All sensory neurons (afferent flow)\n",
    "sensory_neurons = meta[meta['flow'] == 'afferent'][['banc_746_id', 'cell_sub_class', 'cell_type']].drop_duplicates()\n",
    "\n",
    "print(f\"Found {len(sensory_neurons):,} sensory neurons\")\n",
    "\n",
    "# Get unique sensory sub-classes\n",
    "sensory_sub_classes = sorted(sensory_neurons['cell_sub_class'].unique())\n",
    "\n",
    "print(f\"\\nSensory sub-classes (n={len(sensory_sub_classes)}):\")\n",
    "print(\", \".join(sensory_sub_classes[:10]))\n",
    "\n",
    "# Target: All mushroom body dopaminergic neurons\n",
    "mb_dopamine_neurons = meta[\n",
    "    meta['cell_class'] == 'mushroom_body_dopaminergic_neuron'\n",
    "][['banc_746_id', 'cell_sub_class', 'cell_type']].drop_duplicates()\n",
    "\n",
    "print(f\"\\nFound {len(mb_dopamine_neurons):,} mushroom body dopamine neurons\")\n",
    "\n",
    "# Get unique MB dopamine types\n",
    "mb_da_types = sorted(mb_dopamine_neurons['cell_type'].unique())\n",
    "\n",
    "print(f\"MB dopamine types (n={len(mb_da_types)}):\")\n",
    "print(\", \".join(mb_da_types[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Influence Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"Initializing influence calculator...\")\nprint(\"This may take a few minutes for large networks...\\n\")\n\n# Prepare data for InfluenceCalculator\n# The package expects a SQLite database with:\n# - 'edgelist_simple' table with columns: pre, post, count, norm, post_count\n# - 'meta' table with column: root_id (plus any other metadata)\n\n# Check edgelist column names and rename if needed\nedgelist_cols = list(edgelist_filtered.columns)\nprint(f\"Edgelist columns: {', '.join(edgelist_cols)}\")\n\nif 'pre' in edgelist_cols and 'post' in edgelist_cols:\n    edgelist_for_ic = edgelist_filtered.copy()\nelse:\n    # Need to rename columns\n    pre_col = f\"pre_{DATASET_ID}\"\n    post_col = f\"post_{DATASET_ID}\"\n    \n    edgelist_for_ic = edgelist_filtered.rename(columns={\n        pre_col: 'pre',\n        post_col: 'post'\n    })\n\n# Add post_count column if not present (required by InfluenceCalculator)\nif 'post_count' not in edgelist_for_ic.columns:\n    edgelist_for_ic['post_count'] = edgelist_for_ic['count'] / edgelist_for_ic['norm']\n\n# Prepare metadata with root_id column\nmeta_for_ic = meta.rename(columns={DATASET_ID: 'root_id'})\n\n# Convert ID columns to string for SQLite compatibility\nmeta_for_ic['root_id'] = meta_for_ic['root_id'].astype(str)\nedgelist_for_ic['pre'] = edgelist_for_ic['pre'].astype(str)\nedgelist_for_ic['post'] = edgelist_for_ic['post'].astype(str)\n\nprint(f\"\\n✓ Data prepared for influence calculator\")\nprint(f\"  Edgelist: {len(edgelist_for_ic):,} connections\")\nprint(f\"  Metadata: {len(meta_for_ic):,} neurons\\n\")\n\n# Create temporary SQLite database\nimport sqlite3\nimport tempfile\n\ntemp_db = tempfile.NamedTemporaryFile(suffix='.sqlite', delete=False)\ntemp_db_path = temp_db.name\ntemp_db.close()\n\nprint(f\"Creating temporary SQLite database: {temp_db_path}\")\n\nconn = sqlite3.connect(temp_db_path)\n\n# Write tables to database\nprint(\"Writing edgelist to database...\")\nedgelist_for_ic.to_sql('edgelist_simple', conn, if_exists='replace', index=False)\n\nprint(\"Writing metadata to database...\")\nmeta_for_ic.to_sql('meta', conn, if_exists='replace', index=False)\n\nconn.close()\n\nprint(\"✓ Database created successfully\\n\")\n\n# Initialize the influence calculator\n# This uses the InfluenceCalculator Python package\nprint(\"Initializing calculator (this may take several minutes)...\")\n\nic_dataset = InfluenceCalculator(\n    filename=temp_db_path,\n    signed=False,\n    count_thresh=5\n)\n\nprint(\"\\n✓ Influence calculator initialized\")\nprint(\"Network ready for influence calculations\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Influence Scores\n",
    "\n",
    "Now we calculate influence scores from each sensory sub-class to all MB dopaminergic neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(f\"Calculating influence scores for {len(sensory_sub_classes)} sensory sub-classes...\")\nprint(f\"Using {n_cores} cores for parallel processing\\n\")\nprint(\"Note: This will take time - influence calculations involve matrix operations on the full network\\n\")\n\n# Get MB dopamine neuron IDs for filtering\nmb_dopamine_ids = set(mb_dopamine_neurons['banc_746_id'].astype(str).values)\n\n# Define function to calculate influence for one sensory sub-class\ndef calculate_influence_for_subclass(i, sensory_sub_class):\n    \"\"\"Calculate influence from one sensory sub-class to MB dopamine neurons.\"\"\"\n    # Get IDs for this sensory sub-class (as strings to match database)\n    sensory_ids = sensory_neurons[\n        sensory_neurons['cell_sub_class'] == sensory_sub_class\n    ]['banc_746_id'].astype(str).tolist()\n    \n    # Skip if no neurons found\n    if len(sensory_ids) == 0:\n        return None\n    \n    # Calculate influence from this sensory sub-class\n    influence_df = ic_dataset.calculate_influence(\n        seed_ids=sensory_ids,\n        silenced_neurons=[]\n    )\n    \n    # Ensure id is string type\n    influence_df['id'] = influence_df['id'].astype(str)\n    \n    # Find the influence score column (may have different names)\n    influence_col = [col for col in influence_df.columns if 'Influence_score' in col][0]\n    \n    # Add adjusted influence (log-transform with offset, floor at 0)\n    adjusted_inf = np.log(influence_df[influence_col]) + 24\n    adjusted_inf[adjusted_inf < 0] = 0\n    influence_df['adjusted_influence'] = adjusted_inf\n    \n    # Filter to MB dopamine neurons and join with metadata\n    influence_scores = influence_df[\n        influence_df['id'].isin(mb_dopamine_ids)\n    ].merge(\n        meta[['banc_746_id', 'cell_sub_class', 'cell_type']].drop_duplicates().assign(\n            banc_746_id=lambda x: x['banc_746_id'].astype(str)\n        ),\n        left_on='id',\n        right_on='banc_746_id',\n        how='left'\n    ).rename(columns={\n        'cell_sub_class': 'target_class',\n        'cell_type': 'target_type'\n    })\n    \n    influence_scores['source'] = sensory_sub_class\n    \n    return influence_scores\n\n# Run calculations in parallel with progress reporting\nfrom tqdm.auto import tqdm\n\nprint(\"Running parallel influence calculations...\")\nall_influence_scores_list = Parallel(n_jobs=n_cores, verbose=10)(\n    delayed(calculate_influence_for_subclass)(i, sc) \n    for i, sc in enumerate(sensory_sub_classes)\n)\n\n# Remove None results (from empty sensory sub-classes)\nall_influence_scores_list = [df for df in all_influence_scores_list if df is not None]\n\nprint(\"\\n✓ Influence calculations complete\\n\")\n\n# Combine all results\nall_influence_scores = pd.concat(all_influence_scores_list, ignore_index=True)\n\nprint(f\"Total influence scores calculated: {len(all_influence_scores):,}\")\n\n# Show sample of results\nprint(\"\\nSample of influence scores:\")\ndisplay_cols = ['source', 'id', 'adjusted_influence', 'target_type']\n# Find the influence column name\ninfluence_col = [col for col in all_influence_scores.columns if 'Influence_score' in col]\nif influence_col:\n    display_cols.insert(2, influence_col[0])\n\nprint(all_influence_scores[display_cols].head(10).to_string())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate by Cell Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Find the influence column name dynamically\ninfluence_col = [col for col in all_influence_scores.columns if 'Influence_score' in col]\nif not influence_col:\n    raise ValueError(\"No Influence_score column found in results\")\ninfluence_col = influence_col[0]\n\n# Aggregate influence scores by source and target cell type\nall_influence_scores_ct = all_influence_scores.groupby(\n    ['source', 'target_type']\n).agg({\n    influence_col: 'sum',\n    'adjusted_influence': 'sum',\n    'id': 'count'\n}).reset_index().rename(columns={\n    'id': 'n_targets',\n    influence_col: 'influence'\n})\n\n# Filter out missing values\nall_influence_scores_ct = all_influence_scores_ct[\n    all_influence_scores_ct['target_type'].notna() & \n    all_influence_scores_ct['source'].notna()\n]\n\nprint(f\"Aggregated to {len(all_influence_scores_ct):,} source-target type pairs\")\n\n# Show top influences\nprint(\"\\nTop 10 sensory → dopamine influences:\")\nprint(all_influence_scores_ct.nlargest(10, 'adjusted_influence')[[\n    'source', 'target_type', 'adjusted_influence', 'n_targets'\n]].to_string())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation: Influence Heatmap\n",
    "\n",
    "Let's create an interactive heatmap showing influence from sensory sub-classes to dopamine neuron types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a matrix for heatmap\n",
    "influence_matrix = all_influence_scores_ct.pivot(\n",
    "    index='source',\n",
    "    columns='target_type',\n",
    "    values='adjusted_influence'\n",
    ").fillna(0)\n",
    "\n",
    "print(f\"Heatmap matrix dimensions: {influence_matrix.shape[0]} x {influence_matrix.shape[1]}\\n\")\n",
    "\n",
    "# Perform hierarchical clustering\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "# Cluster rows (sources)\n",
    "row_linkage = linkage(pdist(influence_matrix.values, metric='euclidean'), method='ward')\n",
    "row_order = leaves_list(row_linkage)\n",
    "\n",
    "# Cluster columns (targets)\n",
    "col_linkage = linkage(pdist(influence_matrix.T.values, metric='euclidean'), method='ward')\n",
    "col_order = leaves_list(col_linkage)\n",
    "\n",
    "# Reorder matrix\n",
    "influence_matrix_ordered = influence_matrix.iloc[row_order, col_order]\n",
    "\n",
    "# Create interactive heatmap with plotly\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=influence_matrix_ordered.values,\n",
    "    x=influence_matrix_ordered.columns,\n",
    "    y=influence_matrix_ordered.index,\n",
    "    colorscale='YlOrRd',\n",
    "    hovertemplate='Source: %{y}<br>Target: %{x}<br>Adjusted Influence: %{z:.2f}<extra></extra>'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Sensory Influence on MB Dopaminergic Neurons',\n",
    "    xaxis_title='Target: MB Dopamine Neuron Type',\n",
    "    yaxis_title='Source: Sensory Sub-Class',\n",
    "    width=1200,\n",
    "    height=1000,\n",
    "    xaxis={'tickangle': -45, 'tickfont': {'size': 8}},\n",
    "    yaxis={'tickfont': {'size': 8}}\n",
    ")\n",
    "\n",
    "# Save as HTML\n",
    "fig.write_html(f\"{IMG_DIR}/{DATASET}_influence_heatmap.html\")\n",
    "\n",
    "print(\"✓ Interactive heatmap saved\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation: UMAP of Influence Patterns\n",
    "\n",
    "We can also visualise the influence patterns using UMAP, where each point is a dopaminergic neuron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate influence by individual neuron\n",
    "all_influence_scores_n = all_influence_scores.groupby(\n",
    "    ['source', 'id']\n",
    ").agg({\n",
    "    'Influence_score_(unsigned)': 'sum',\n",
    "    'adjusted_influence': 'sum',\n",
    "    'target_type': 'first',\n",
    "    'target_class': 'first'\n",
    "}).reset_index().rename(columns={\n",
    "    'Influence_score_(unsigned)': 'influence'\n",
    "})\n",
    "\n",
    "all_influence_scores_n = all_influence_scores_n[\n",
    "    all_influence_scores_n['id'].notna() & \n",
    "    all_influence_scores_n['source'].notna()\n",
    "]\n",
    "\n",
    "# Create matrix: rows = neurons, columns = sensory sub-classes\n",
    "influence_matrix_umap = all_influence_scores_n.pivot(\n",
    "    index='id',\n",
    "    columns='source',\n",
    "    values='adjusted_influence'\n",
    ").fillna(0)\n",
    "\n",
    "print(f\"UMAP input matrix: {influence_matrix_umap.shape[0]} neurons x {influence_matrix_umap.shape[1]} sensory sub-classes\\n\")\n",
    "\n",
    "# Run UMAP\n",
    "import umap.umap_ as umap_lib\n",
    "\n",
    "reducer = umap_lib.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "umap_result = reducer.fit_transform(influence_matrix_umap.values)\n",
    "\n",
    "# Create data frame for plotting\n",
    "umap_df = pd.DataFrame({\n",
    "    'id': influence_matrix_umap.index,\n",
    "    'UMAP1': umap_result[:, 0],\n",
    "    'UMAP2': umap_result[:, 1]\n",
    "}).merge(\n",
    "    meta[['banc_746_id', 'cell_type', 'cell_sub_class', 'cell_class']].drop_duplicates(),\n",
    "    left_on='id',\n",
    "    right_on='banc_746_id'\n",
    ")\n",
    "\n",
    "# Plot by cell sub-class\n",
    "fig = px.scatter(\n",
    "    umap_df,\n",
    "    x='UMAP1',\n",
    "    y='UMAP2',\n",
    "    color='cell_sub_class',\n",
    "    title=f'UMAP of MB Dopamine Neurons by Sensory Influence Patterns (n = {len(umap_df)})',\n",
    "    labels={'cell_sub_class': 'Cell Sub-Class'},\n",
    "    width=1200,\n",
    "    height=600,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=8, opacity=0.7))\n",
    "fig.write_html(f\"{IMG_DIR}/{DATASET}_influence_umap_subclass.html\")\n",
    "fig.show()\n",
    "\n",
    "# Plot by cell type\n",
    "fig = px.scatter(\n",
    "    umap_df,\n",
    "    x='UMAP1',\n",
    "    y='UMAP2',\n",
    "    color='cell_type',\n",
    "    title=f'UMAP of MB Dopamine Neurons by Sensory Influence Patterns (n = {len(umap_df)})',\n",
    "    labels={'cell_type': 'Cell Type'},\n",
    "    width=1200,\n",
    "    height=600,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=8, opacity=0.7))\n",
    "fig.write_html(f\"{IMG_DIR}/{DATASET}_influence_umap_type.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "From this analysis, we can see:\n",
    "\n",
    "1. **Diverse sensory influences**: MB dopaminergic neurons receive influence from many sensory modalities through both direct and indirect pathways\n",
    "2. **Cell type specificity**: Different dopamine neuron types show distinct sensory influence patterns\n",
    "3. **Indirect pathways**: Influence scores capture multi-synaptic signal propagation beyond direct connections\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this tutorial, you learned how to:\n",
    "\n",
    "1. ✓ Calculate indirect connectivity using the influence metric\n",
    "2. ✓ Set up and use the InfluenceCalculator package\n",
    "3. ✓ Analyse influence from sensory neurons to dopaminergic neurons\n",
    "4. ✓ Visualise influence patterns with heatmaps and UMAP\n",
    "5. ✓ Interpret biological significance of influence scores\n",
    "\n",
    "The influence metric provides a powerful way to understand how signals propagate through neural circuits beyond direct synaptic connections."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}