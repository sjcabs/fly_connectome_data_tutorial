{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Runtime Configuration:** This notebook has a paired setup script at `runtimes/fly_connectome_03_connectivity_analyses_post_startup.sh` which provides the complete installation recipe for all dependencies. This script can be used as a post-startup script for Google Colab to automatically configure the environment.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš ï¸ Setup Instructions for Google Colab\n",
    "\n",
    "Before running this notebook in Google Colab, you MUST run the paired runtime script to install dependencies.\n",
    "\n",
    "**Option 1: Automatic Post-Startup Script (Recommended)**\n",
    "1. Go to: **Runtime â†’ Change runtime type â†’ Advanced settings**\n",
    "2. Under \"Post-startup script\", enter the raw GitHub URL:\n",
    "   ```\n",
    "   https://raw.githubusercontent.com/sjcabs/fly_connectome_data_tutorial/main/python/runtimes/fly_connectome_XX_post_startup.sh\n",
    "   ```\n",
    "   (Replace `XX` with `01`, `02`, `03`, or `04` to match this tutorial)\n",
    "3. Click **Save** and start the runtime\n",
    "\n",
    "**Option 2: Manual Execution**\n",
    "Run this in a cell before starting:\n",
    "```python\n",
    "!wget https://raw.githubusercontent.com/sjcabs/fly_connectome_data_tutorial/main/python/runtimes/fly_connectome_XX_post_startup.sh\n",
    "!bash fly_connectome_XX_post_startup.sh\n",
    "```\n",
    "\n",
    "**Recommended Colab Machine:** Colab Pro (25-30 GB RAM) for best performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core Tutorial\n",
    "\n",
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download utils.py if not available (for Google Colab)\n",
    "import os\n",
    "if not os.path.exists('utils.py'):\n",
    "    print('ðŸ“¥ Downloading utils.py from GitHub...')\n",
    "    import urllib.request\n",
    "    url = 'https://raw.githubusercontent.com/sjcabs/fly_connectome_data_tutorial/main/python/utils.py'\n",
    "    urllib.request.urlretrieve(url, 'utils.py')\n",
    "    print('âœ“ Downloaded utils.py')\n",
    "else:\n",
    "    print('âœ“ utils.py already available')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T19:32:58.702888Z",
     "iopub.status.busy": "2025-12-29T19:32:58.702753Z",
     "iopub.status.idle": "2025-12-29T19:32:58.709970Z",
     "shell.execute_reply": "2025-12-29T19:32:58.709117Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset configuration\n",
    "# Options: \"banc_746\", \"fafb_783\", \"manc_121\", \"hemibrain_121\", \"malecns_09\"\n",
    "DATASET = \"banc_746\"\n",
    "DATASET_ID = \"banc_746_id\"\n",
    "SUBSET_NAME = \"front_leg\"  # Optional: use subset data if available\n",
    "\n",
    "# Data location - can be GCS bucket or local path\n",
    "# Option 1 (GCS - default): Access data directly from Google Cloud Storage\n",
    "DATA_PATH = \"gs://sjcabs_2025_data\"\n",
    "\n",
    "# Option 2 (Local): Use local copy if you've downloaded the data\n",
    "# DATA_PATH = \"/path/to/local/sjcabs_data\"\n",
    "# Example: DATA_PATH = \"~/data/sjcabs_data\"\n",
    "\n",
    "# Detect if using GCS or local path\n",
    "USE_GCS = DATA_PATH.startswith(\"gs://\")\n",
    "\n",
    "# Image output directory\n",
    "import os\n",
    "IMG_DIR = \"images/tutorial_03\"\n",
    "os.makedirs(IMG_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Dataset: {DATASET}\")\n",
    "print(f\"Data location: {DATA_PATH}\")\n",
    "print(f\"Using GCS: {USE_GCS}\")\n",
    "print(f\"Images will be saved to: {IMG_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T19:32:58.738258Z",
     "iopub.status.busy": "2025-12-29T19:32:58.738104Z",
     "iopub.status.idle": "2025-12-29T19:32:58.741381Z",
     "shell.execute_reply": "2025-12-29T19:32:58.740952Z"
    }
   },
   "outputs": [],
   "source": [
    "# Environment detection and Colab setup (auto-configured)\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    \n",
    "    # Colab setup\n",
    "    \n",
    "    # Authenticate\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    print(\"âœ“ Authenticated with Google Cloud\")\n",
    "    \n",
    "    # Download utils.py\n",
    "    import urllib.request, os\n",
    "    HELPER_URL = \"https://raw.githubusercontent.com/sjcabs/fly_connectome_data_tutorial/main/python/utils.py\"\n",
    "    if not os.path.exists(\"utils.py\"):\n",
    "        urllib.request.urlretrieve(HELPER_URL, \"setup_helpers.py\")\n",
    "    \n",
    "    print(\"âœ“ Colab environment ready\\n\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    # Local environment - no output needed\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T19:32:58.743052Z",
     "iopub.status.busy": "2025-12-29T19:32:58.742937Z",
     "iopub.status.idle": "2025-12-29T19:33:05.838091Z",
     "shell.execute_reply": "2025-12-29T19:33:05.837023Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import standard packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gcsfs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "import networkx as nx\n",
    "import umap\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster, cut_tree\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import neuroscience packages\n",
    "import navis\n",
    "import trimesh\n",
    "\n",
    "# Configure plotly renderer\n",
    "try:\n",
    "    import google.colab\n",
    "    pio.renderers.default = \"colab\"\n",
    "except ImportError:\n",
    "    pio.renderers.default = \"notebook\"\n",
    "\n",
    "# Import helper functions from utils module\n",
    "from utils import construct_path, read_feather_gcs, batch_read_swc_from_gcs\n",
    "\n",
    "print(\"âœ“ All packages and helper functions imported\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup GCS Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T19:33:05.840817Z",
     "iopub.status.busy": "2025-12-29T19:33:05.840354Z",
     "iopub.status.idle": "2025-12-29T19:33:05.846111Z",
     "shell.execute_reply": "2025-12-29T19:33:05.845357Z"
    }
   },
   "outputs": [],
   "source": [
    "if USE_GCS:\n",
    "    gcs = gcsfs.GCSFileSystem(token='google_default')\n",
    "    print(\"âœ“ GCS filesystem initialized\")\n",
    "else:\n",
    "    gcs = None\n",
    "    print(\"Using local filesystem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "We'll load:\n",
    "1. **Metadata** - neuron annotations\n",
    "2. **Edgelist** - neuron-to-neuron connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T19:33:05.848177Z",
     "iopub.status.busy": "2025-12-29T19:33:05.848004Z",
     "iopub.status.idle": "2025-12-29T19:33:05.851828Z",
     "shell.execute_reply": "2025-12-29T19:33:05.851172Z"
    }
   },
   "outputs": [],
   "source": [
    "# Construct edgelist path (use subset if specified)\n",
    "dataset_base = DATASET.split(\"_\")[0]\n",
    "\n",
    "if SUBSET_NAME is not None:\n",
    "    # Use subset-specific edgelist\n",
    "    subset_dir = f\"{DATA_PATH}/{dataset_base}/{SUBSET_NAME}\"\n",
    "    edgelist_filename = f\"{DATASET}_{SUBSET_NAME}_simple_edgelist.feather\"\n",
    "    edgelist_path = f\"{subset_dir}/{edgelist_filename}\"\n",
    "    print(f\"Using subset: {SUBSET_NAME}\")\n",
    "else:\n",
    "    # Use full edgelist\n",
    "    edgelist_path = construct_path(DATA_PATH, DATASET, \"edgelist_simple\")\n",
    "    print(\"Using full dataset (this may be slow)\")\n",
    "\n",
    "print(f\"Edgelist path: {edgelist_path}\")\n",
    "\n",
    "# Meta path (always uses full meta, not subset)\n",
    "meta_path = construct_path(DATA_PATH, DATASET, \"meta\")\n",
    "print(f\"Meta path: {meta_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T19:33:05.853538Z",
     "iopub.status.busy": "2025-12-29T19:33:05.853397Z",
     "iopub.status.idle": "2025-12-29T19:33:05.918132Z",
     "shell.execute_reply": "2025-12-29T19:33:05.917697Z"
    }
   },
   "outputs": [],
   "source": [
    "meta = read_feather_gcs(meta_path, gcs_fs=gcs)\n",
    "\n",
    "print(f\"\\nTotal neurons: {len(meta):,}\")\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Edgelist (Connectivity Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T19:33:05.919744Z",
     "iopub.status.busy": "2025-12-29T19:33:05.919630Z",
     "iopub.status.idle": "2025-12-29T19:33:05.974447Z",
     "shell.execute_reply": "2025-12-29T19:33:05.974015Z"
    }
   },
   "outputs": [],
   "source": [
    "edgelist = read_feather_gcs(edgelist_path, gcs_fs=gcs)\n",
    "\n",
    "# Rename norm column to weight for consistency\n",
    "if 'norm' in edgelist.columns and 'weight' not in edgelist.columns:\n",
    "    edgelist['weight'] = edgelist['norm']\n",
    "\n",
    "print(f\"\\nTotal connections: {len(edgelist):,}\")\n",
    "print(f\"Columns: {list(edgelist.columns)}\")\n",
    "edgelist.head()\n",
    "# Filter meta to neurons present in edgelist (matches R version)\n",
    "neuron_ids = set(edgelist[\"pre\"].unique()) | set(edgelist[\"post\"].unique())\n",
    "meta = meta[meta[DATASET_ID].isin(neuron_ids)].copy()\n",
    "print(f\"Filtered meta to {len(meta):,} neurons present in edgelist\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Neuropil Meshes\n",
    "\n",
    "Before analyzing connectivity, let's visualize the 3D structure of the suboesophageal zone (SEZ) neuropils to understand their spatial organization.\n",
    "\n",
    "**Mesh organization:**\n",
    "- **Large anatomical regions** (VNC, brain, etc.): `obj/` directory\n",
    "- **Smaller specific neuropils** (GNG, FLA, AMMC, etc.): `obj/neuropils/` subdirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T19:33:05.976218Z",
     "iopub.status.busy": "2025-12-29T19:33:05.976089Z",
     "iopub.status.idle": "2025-12-29T19:33:13.082520Z",
     "shell.execute_reply": "2025-12-29T19:33:13.081753Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helper function to load neuropil meshes\n",
    "def load_neuropil_mesh(search_pattern, data_path, dataset_base, subdirectory=\"neuropils\"):\n",
    "    \"\"\"Load a neuropil mesh from GCS and convert to navis.Volume\"\"\"\n",
    "    if subdirectory:\n",
    "        mesh_path = f\"{data_path}/{dataset_base}/obj/{subdirectory}\"\n",
    "    else:\n",
    "        mesh_path = f\"{data_path}/{dataset_base}/obj\"\n",
    "    \n",
    "    if USE_GCS:\n",
    "        gcs_mesh_path = mesh_path.replace(\"gs://\", \"\")\n",
    "        try:\n",
    "            mesh_files = gcs.ls(gcs_mesh_path)\n",
    "            mesh_files = [f\"gs://{f}\" for f in mesh_files if f.endswith('.obj')]\n",
    "        except:\n",
    "            print(f\"  Could not list files in {mesh_path}\")\n",
    "            return None\n",
    "    else:\n",
    "        import glob\n",
    "        mesh_files = glob.glob(f\"{mesh_path}/*.obj\")\n",
    "    \n",
    "    # Find files matching the search pattern\n",
    "    matching_files = [f for f in mesh_files if search_pattern.lower() in f.lower()]\n",
    "    \n",
    "    if len(matching_files) == 0:\n",
    "        print(f\"  No files found matching: {search_pattern}\")\n",
    "        return None\n",
    "    \n",
    "    # Load the first matching file\n",
    "    mesh_file = matching_files[0]\n",
    "    \n",
    "    try:\n",
    "        if USE_GCS:\n",
    "            mesh = read_obj_from_gcs(gcs, mesh_file.replace('gs://', ''))\n",
    "        else:\n",
    "            mesh = trimesh.load(mesh_file)\n",
    "        \n",
    "        # Convert trimesh to navis.Volume\n",
    "        volume = navis.Volume(mesh.vertices, mesh.faces, name=search_pattern)\n",
    "        return volume\n",
    "    except Exception as e:\n",
    "        print(f\"  Failed to load {search_pattern}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load brain mesh (large region, for context)\n",
    "print(\"Loading neuropil meshes...\")\n",
    "brain_volume = load_neuropil_mesh(\"brain\", DATA_PATH, dataset_base, subdirectory=\"\")\n",
    "\n",
    "# Load SEZ neuropils (smaller specific regions)\n",
    "gng_volume = load_neuropil_mesh(\"GNG\", DATA_PATH, dataset_base)\n",
    "fla_l_volume = load_neuropil_mesh(\"FLA_L\", DATA_PATH, dataset_base)\n",
    "fla_r_volume = load_neuropil_mesh(\"FLA_R\", DATA_PATH, dataset_base)\n",
    "sad_volume = load_neuropil_mesh(\"SAD\", DATA_PATH, dataset_base)\n",
    "prw_volume = load_neuropil_mesh(\"PRW\", DATA_PATH, dataset_base)\n",
    "ammc_l_volume = load_neuropil_mesh(\"AMMC_L\", DATA_PATH, dataset_base)\n",
    "ammc_r_volume = load_neuropil_mesh(\"AMMC_R\", DATA_PATH, dataset_base)\n",
    "\n",
    "# Collect all loaded volumes and set their colors/alphas\n",
    "volumes = []\n",
    "\n",
    "if brain_volume:\n",
    "    brain_volume.color = (0.827, 0.827, 0.827, 0.1)  # lightgrey with alpha=0.1\n",
    "    volumes.append(brain_volume)\n",
    "\n",
    "if gng_volume:\n",
    "    gng_volume.color = (1.0, 0.0, 0.0, 0.5)  # red with alpha=0.5\n",
    "    volumes.append(gng_volume)\n",
    "\n",
    "if fla_l_volume:\n",
    "    fla_l_volume.color = (0.0, 0.0, 1.0, 0.5)  # blue with alpha=0.5\n",
    "    volumes.append(fla_l_volume)\n",
    "\n",
    "if fla_r_volume:\n",
    "    fla_r_volume.color = (0.678, 0.847, 0.902, 0.5)  # lightblue with alpha=0.5\n",
    "    volumes.append(fla_r_volume)\n",
    "\n",
    "if sad_volume:\n",
    "    sad_volume.color = (0.0, 0.502, 0.0, 0.5)  # green with alpha=0.5\n",
    "    volumes.append(sad_volume)\n",
    "\n",
    "if prw_volume:\n",
    "    prw_volume.color = (0.502, 0.0, 0.502, 0.5)  # purple with alpha=0.5\n",
    "    volumes.append(prw_volume)\n",
    "\n",
    "if ammc_l_volume:\n",
    "    ammc_l_volume.color = (1.0, 0.647, 0.0, 0.5)  # orange with alpha=0.5\n",
    "    volumes.append(ammc_l_volume)\n",
    "\n",
    "if ammc_r_volume:\n",
    "    ammc_r_volume.color = (1.0, 0.627, 0.478, 0.5)  # lightsalmon with alpha=0.5\n",
    "    volumes.append(ammc_r_volume)\n",
    "\n",
    "# Plot all neuropils in 3D using navis\n",
    "if len(volumes) > 0:\n",
    "    print(f\"\\nâœ“ Loaded {len(volumes)} neuropil meshes\")\n",
    "    print(\"Visualizing neuropils with navis...\")\n",
    "    \n",
    "    # Plot with navis - colors/alphas are set on Volume objects\n",
    "    fig = navis.plot3d(\n",
    "        volumes,\n",
    "        backend='plotly',\n",
    "        width=1200,\n",
    "        height=800,\n",
    "        title='Suboesophageal Zone Neuropils'\n",
    "    )\n",
    "    \n",
    "    if fig is not None:\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"Note: Plot was displayed inline\")\n",
    "else:\n",
    "    print(\"âš  No neuropil meshes loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta Data Overview\n",
    "\n",
    "Let's examine the distribution of neurons by `super_class` and `cell_class` in our subset.\n",
    "\n",
    "### Neurotransmitter Consensus\n",
    "\n",
    "First, we'll establish consensus neurotransmitter for each neuron based on prediction scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T19:33:13.103982Z",
     "iopub.status.busy": "2025-12-29T19:33:13.103800Z",
     "iopub.status.idle": "2025-12-29T19:33:13.108357Z",
     "shell.execute_reply": "2025-12-29T19:33:13.107975Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get neurotransmitter with highest score for each neuron\n",
    "meta['nt'] = meta['neurotransmitter_predicted']\n",
    "\n",
    "# Classify as excitatory or inhibitory\n",
    "excitatory_nts = ['acetylcholine', 'glutamate']\n",
    "inhibitory_nts = ['gaba', 'glycine']\n",
    "\n",
    "meta['nt_type'] = 'other'\n",
    "meta.loc[meta['nt'].isin(excitatory_nts), 'nt_type'] = 'excitatory'\n",
    "meta.loc[meta['nt'].isin(inhibitory_nts), 'nt_type'] = 'inhibitory'\n",
    "\n",
    "print(\"Neurotransmitter distribution:\")\n",
    "print(meta['nt'].value_counts())\n",
    "print(\"\\nNeurotransmitter type distribution:\")\n",
    "print(meta['nt_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neurotransmitter Prediction and Connectivity Signs\n",
    "\n",
    "To understand whether connections are excitatory or inhibitory, we use predicted neurotransmitter information.\n",
    "\n",
    "We'll assign signs to connections:\n",
    "- **Excitatory** (sign: +1): acetylcholine, glutamate\n",
    "- **Inhibitory** (sign: -1): GABA, glycine\n",
    "\n",
    "This creates signed connectivity weights that capture both connection strength and likely sign.\n",
    "\n",
    "### Add Signed Connectivity\n",
    "\n",
    "Infer edge sign based on presynaptic neuron's neurotransmitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T19:33:13.109799Z",
     "iopub.status.busy": "2025-12-29T19:33:13.109714Z",
     "iopub.status.idle": "2025-12-29T19:33:13.158662Z",
     "shell.execute_reply": "2025-12-29T19:33:13.158183Z"
    }
   },
   "outputs": [],
   "source": [
    "# Map neurotransmitter types to edges\n",
    "nt_map = dict(zip(meta[DATASET_ID], meta['nt_type']))\n",
    "edgelist['nt_type'] = edgelist['pre'].map(nt_map)\n",
    "\n",
    "# Assign sign: excitatory = +1, inhibitory = -1, other = 0\n",
    "edgelist['sign'] = 0\n",
    "edgelist.loc[edgelist['nt_type'] == 'excitatory', 'sign'] = 1\n",
    "edgelist.loc[edgelist['nt_type'] == 'inhibitory', 'sign'] = -1\n",
    "\n",
    "# Create signed weight\n",
    "edgelist['weight_signed'] = edgelist['weight'] * edgelist['sign']\n",
    "\n",
    "print(f\"\\nâœ“ Added signed connectivity\")\n",
    "print(f\"Excitatory edges: {(edgelist['sign'] == 1).sum():,}\")\n",
    "print(f\"Inhibitory edges: {(edgelist['sign'] == -1).sum():,}\")\n",
    "print(f\"Other edges: {(edgelist['sign'] == 0).sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signed Weight Distribution\n",
    "\n",
    "Let's visualize the distribution of signed connection weights to compare excitatory and inhibitory connections.\n",
    "\n",
    "**Note:** While this signed classification is useful for circuit diagrams, it's important not to overstate its precision. In flies, glutamate can be excitatory or inhibitory, and inhibition doesn't only quell activity - it can enable it through disinhibition. Consider the visual system where histaminergic photoreceptors inhibit their targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T19:33:13.160329Z",
     "iopub.status.busy": "2025-12-29T19:33:13.160218Z",
     "iopub.status.idle": "2025-12-29T19:33:13.726064Z",
     "shell.execute_reply": "2025-12-29T19:33:13.725433Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter edges with non-zero sign for visualization\n",
    "edgelist_signed = edgelist[edgelist['sign'] != 0].copy()\n",
    "\n",
    "# Create histogram of signed weights\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=edgelist_signed[edgelist_signed['sign'] == 1]['weight'],\n",
    "    name='Excitatory',\n",
    "    marker_color='red',\n",
    "    opacity=0.7,\n",
    "    nbinsx=50\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=edgelist_signed[edgelist_signed['sign'] == -1]['weight'],\n",
    "    name='Inhibitory',\n",
    "    marker_color='blue',\n",
    "    opacity=0.7,\n",
    "    nbinsx=50\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Distribution of Signed Connection Weights',\n",
    "    xaxis_title='Connection Weight (synapse count)',\n",
    "    yaxis_title='Count',\n",
    "    barmode='overlay',\n",
    "    template='plotly_white',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.write_html(f\"{IMG_DIR}/{DATASET}_signed_weight_distribution.html\")\n",
    "fig.show()\n",
    "\n",
    "print(f\"âœ“ Saved signed weight distribution plot\")\n",
    "print(f\"Excitatory connections: {(edgelist['sign'] == 1).sum():,}\")\n",
    "print(f\"Inhibitory connections: {(edgelist['sign'] == -1).sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuron Class Distribution\n",
    "\n",
    "Let's examine the distribution of neurons by super_class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T19:33:13.878106Z",
     "iopub.status.busy": "2025-12-29T19:33:13.877970Z",
     "iopub.status.idle": "2025-12-29T19:33:13.940981Z",
     "shell.execute_reply": "2025-12-29T19:33:13.940604Z"
    }
   },
   "outputs": [],
   "source": [
    "# Count neurons by super_class\n",
    "super_class_counts = meta['super_class'].value_counts().reset_index()\n",
    "super_class_counts.columns = ['super_class', 'count']\n",
    "\n",
    "# Create bar plot\n",
    "fig = px.bar(\n",
    "    super_class_counts,\n",
    "    x='super_class',\n",
    "    y='count',\n",
    "    color='super_class',\n",
    "    title='Neuron Distribution by Super Class',\n",
    "    labels={'super_class': 'Super Class', 'count': 'Number of Neurons'},\n",
    "    template='plotly_white',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.update_layout(showlegend=False, xaxis_tickangle=-45)\n",
    "fig.write_html(f\"{IMG_DIR}/{DATASET}_super_class.html\")\n",
    "fig.show()\n",
    "\n",
    "print(f\"âœ“ Saved super_class distribution plot\")\n",
    "print(f\"\\nSuper class distribution:\")\n",
    "print(super_class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Network Statistics\n",
    "\n",
    "Next, we'll examine basic properties of the connectivity graph using network analysis.\n",
    "\n",
    "### Weight Correlation Analysis\n",
    "\n",
    "Examine the relationship between synapse count and normalized weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow Subclass Analysis\n",
    "\n",
    "If we have sensory (afferent) or effector (efferent) neurons, let's examine their cell sub-classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T19:33:13.942849Z",
     "iopub.status.busy": "2025-12-29T19:33:13.942747Z",
     "iopub.status.idle": "2025-12-29T19:33:14.003471Z",
     "shell.execute_reply": "2025-12-29T19:33:14.002916Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get sensory and effector neurons\n",
    "flow_subset = meta[meta['flow'].isin(['afferent', 'efferent'])].copy()\n",
    "\n",
    "if len(flow_subset) > 0:\n",
    "    # Get top 15 cell sub-classes per flow type\n",
    "    flow_counts = flow_subset.groupby(['flow', 'cell_sub_class']).size().reset_index(name='count')\n",
    "    top_per_flow = flow_counts.sort_values(['flow', 'count'], ascending=[True, False])\n",
    "    top_per_flow = top_per_flow.groupby('flow').head(15)\n",
    "    \n",
    "    # Rename flow types for display\n",
    "    top_per_flow['flow_label'] = top_per_flow['flow'].map({\n",
    "        'afferent': 'Sensory (afferent)',\n",
    "        'efferent': 'Effector (efferent)'\n",
    "    })\n",
    "    \n",
    "    # Create faceted bar plot\n",
    "    fig = px.bar(\n",
    "        top_per_flow,\n",
    "        x='cell_sub_class',\n",
    "        y='count',\n",
    "        color='cell_sub_class',\n",
    "        facet_col='flow_label',\n",
    "        title='Top 15 Cell Sub-Classes per Flow Type',\n",
    "        labels={'cell_sub_class': 'Cell Sub-Class', 'count': 'Number of Neurons'},\n",
    "        template='plotly_white',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(tickangle=-45)\n",
    "    fig.update_layout(showlegend=False)\n",
    "    fig.write_html(f\"{IMG_DIR}/{DATASET}_flow_subclass.html\")\n",
    "    fig.show()\n",
    "    \n",
    "    print(f\"âœ“ Saved flow subclass plot\")\n",
    "    print(f\"Sensory neuron count: {(flow_subset['flow'] == 'afferent').sum():,}\")\n",
    "    print(f\"Effector neuron count: {(flow_subset['flow'] == 'efferent').sum():,}\")\n",
    "else:\n",
    "    print(\"No sensory or effector neurons in this subset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T19:33:14.007416Z",
     "iopub.status.busy": "2025-12-29T19:33:14.007290Z",
     "iopub.status.idle": "2025-12-29T19:33:14.143704Z",
     "shell.execute_reply": "2025-12-29T19:33:14.143185Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sample if too many points\n",
    "if len(edgelist) > 50000:\n",
    "    edgelist_sample = edgelist.sample(n=50000, random_state=42)\n",
    "    print(f\"Sampling 50,000 connections for visualization\")\n",
    "else:\n",
    "    edgelist_sample = edgelist\n",
    "\n",
    "# Calculate Spearman correlation\n",
    "from scipy.stats import spearmanr\n",
    "corr, _ = spearmanr(edgelist['count'], edgelist['norm'])\n",
    "\n",
    "# Create scatter plot\n",
    "fig = px.scatter(\n",
    "    edgelist_sample,\n",
    "    x='count',\n",
    "    y='norm',\n",
    "    log_x=True,\n",
    "    log_y=True,\n",
    "    opacity=0.3,\n",
    "    title=f'Relationship between Synapse Count and Normalized Weight<br><sub>Spearman correlation: {corr:.3f}</sub>',\n",
    "    labels={'count': 'Synapse Count (log scale)', 'norm': 'Normalized Weight (log scale)'},\n",
    "    template='plotly_white',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "# Add trendline\n",
    "fig.update_traces(marker=dict(color='steelblue', size=3))\n",
    "\n",
    "fig.write_html(f\"{IMG_DIR}/{DATASET}_weight_correlation.html\")\n",
    "fig.show()\n",
    "\n",
    "print(f\"âœ“ Saved weight correlation plot\")\n",
    "print(f\"Spearman correlation: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree Distribution\n",
    "\n",
    "Analyze in-degree and out-degree distributions with different synapse count thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T19:33:14.175479Z",
     "iopub.status.busy": "2025-12-29T19:33:14.175357Z",
     "iopub.status.idle": "2025-12-29T19:33:14.263126Z",
     "shell.execute_reply": "2025-12-29T19:33:14.262350Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate in-degree and out-degree with two thresholds\n",
    "degree_data = []\n",
    "\n",
    "# Threshold 1: count > 1\n",
    "in_degree_1 = edgelist[edgelist['count'] > 1].groupby('post').size().reset_index()\n",
    "in_degree_1.columns = ['neuron', 'degree']\n",
    "in_degree_1['type'] = 'In-degree'\n",
    "in_degree_1['threshold'] = '>1 synapse'\n",
    "\n",
    "out_degree_1 = edgelist[edgelist['count'] > 1].groupby('pre').size().reset_index()\n",
    "out_degree_1.columns = ['neuron', 'degree']\n",
    "out_degree_1['type'] = 'Out-degree'\n",
    "out_degree_1['threshold'] = '>1 synapse'\n",
    "\n",
    "# Threshold 2: count > 10\n",
    "in_degree_10 = edgelist[edgelist['count'] > 10].groupby('post').size().reset_index()\n",
    "in_degree_10.columns = ['neuron', 'degree']\n",
    "in_degree_10['type'] = 'In-degree'\n",
    "in_degree_10['threshold'] = '>10 synapses'\n",
    "\n",
    "out_degree_10 = edgelist[edgelist['count'] > 10].groupby('pre').size().reset_index()\n",
    "out_degree_10.columns = ['neuron', 'degree']\n",
    "out_degree_10['type'] = 'Out-degree'\n",
    "out_degree_10['threshold'] = '>10 synapses'\n",
    "\n",
    "# Combine all\n",
    "degree_data = pd.concat([in_degree_1, out_degree_1, in_degree_10, out_degree_10], ignore_index=True)\n",
    "\n",
    "# Create density plot using histogram\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=('>1 synapse', '>10 synapses'))\n",
    "\n",
    "for i, threshold in enumerate(['>1 synapse', '>10 synapses']):\n",
    "    subset = degree_data[degree_data['threshold'] == threshold]\n",
    "    \n",
    "    for dtype, color in [('In-degree', 'orange'), ('Out-degree', 'blue')]:\n",
    "        data = subset[subset['type'] == dtype]['degree']\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=np.log10(data),\n",
    "                name=dtype,\n",
    "                marker_color=color,\n",
    "                opacity=0.6,\n",
    "                nbinsx=50,\n",
    "                histnorm='probability density',\n",
    "                showlegend=(i == 0)\n",
    "            ),\n",
    "            row=1, col=i+1\n",
    "        )\n",
    "\n",
    "fig.update_xaxes(title_text=\"Degree (log10 scale)\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Degree (log10 scale)\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Density\", row=1, col=1)\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text='Degree Distribution by Synapse Count Threshold',\n",
    "    height=500,\n",
    "    template='plotly_white',\n",
    "    barmode='overlay'\n",
    ")\n",
    "\n",
    "fig.write_html(f\"{IMG_DIR}/{DATASET}_degree_distribution.html\")\n",
    "fig.show()\n",
    "\n",
    "print(f\"âœ“ Saved degree distribution plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connectivity Matrix\n",
    "\n",
    "One effective way to visualize connectivity is through connectivity matrices, with `pre` on rows and `post` on columns.\n",
    "\n",
    "Since we have many neurons, we'll collapse our edgelist by `cell_type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T19:33:14.269616Z",
     "iopub.status.busy": "2025-12-29T19:33:14.269488Z",
     "iopub.status.idle": "2025-12-29T19:33:14.367573Z",
     "shell.execute_reply": "2025-12-29T19:33:14.366877Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add cell_class to edgelist\n",
    "cell_class_map = dict(zip(meta[DATASET_ID], meta['cell_class']))\n",
    "edgelist['pre_class'] = edgelist['pre'].map(cell_class_map)\n",
    "edgelist['post_class'] = edgelist['post'].map(cell_class_map)\n",
    "\n",
    "# Aggregate by cell_class (sum weights)\n",
    "class_connectivity = edgelist.groupby(['pre_class', 'post_class'])['weight'].sum().reset_index()\n",
    "\n",
    "# Find most connected cell classes\n",
    "top_classes_pre = class_connectivity.groupby('pre_class')['weight'].sum().nlargest(20).index\n",
    "top_classes_post = class_connectivity.groupby('post_class')['weight'].sum().nlargest(20).index\n",
    "top_classes = list(set(top_classes_pre) | set(top_classes_post))\n",
    "\n",
    "# Filter to top classes\n",
    "class_conn_filtered = class_connectivity[\n",
    "    class_connectivity['pre_class'].isin(top_classes) &\n",
    "    class_connectivity['post_class'].isin(top_classes)\n",
    "]\n",
    "\n",
    "# Create pivot table for heatmap\n",
    "conn_matrix = class_conn_filtered.pivot(index='pre_class', columns='post_class', values='weight').fillna(0)\n",
    "\n",
    "# Create heatmap\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=conn_matrix.values,\n",
    "    x=conn_matrix.columns,\n",
    "    y=conn_matrix.index,\n",
    "    colorscale='Viridis',\n",
    "    colorbar=dict(title='Total Weight')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'Connectivity Matrix: Top {len(top_classes)} Cell Classes',\n",
    "    xaxis_title='Postsynaptic Cell Class',\n",
    "    yaxis_title='Presynaptic Cell Class',\n",
    "    height=800,\n",
    "    width=900,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.update_xaxes(tickangle=-45)\n",
    "\n",
    "fig.write_html(f\"{IMG_DIR}/{DATASET}_connectivity_matrix.html\")\n",
    "fig.show()\n",
    "\n",
    "print(f\"âœ“ Saved connectivity matrix heatmap\")\n",
    "print(f\"Matrix dimensions: {conn_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensory and Effector Connectivity\n",
    "\n",
    "In general, sensory neurons (`flow == \"afferent\"`) and effector neurons (`flow == \"efferent\"`) are quite interpretable because their cell_class labels often indicate body part innervation.\n",
    "\n",
    "Let's re-collapse our edgelist using `cell_class` for sensory/effector neurons and `cell_type` for everything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T19:33:14.369638Z",
     "iopub.status.busy": "2025-12-29T19:33:14.369537Z",
     "iopub.status.idle": "2025-12-29T19:33:14.890168Z",
     "shell.execute_reply": "2025-12-29T19:33:14.889776Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create edgelist with mixed labels (cell_class for sensory/effector, cell_type for others)\n",
    "# OPTIMIZED: Use vectorized operations instead of apply()\n",
    "\n",
    "# Create mapping dictionaries from meta\n",
    "id_to_flow = dict(zip(meta[DATASET_ID], meta['flow']))\n",
    "id_to_class = dict(zip(meta[DATASET_ID], meta['cell_class']))\n",
    "id_to_type = dict(zip(meta[DATASET_ID], meta['cell_type']))\n",
    "\n",
    "\n",
    "# Map flow for pre and post\n",
    "edgelist['pre_flow'] = edgelist['pre'].map(id_to_flow)\n",
    "edgelist['post_flow'] = edgelist['post'].map(id_to_flow)\n",
    "\n",
    "# Create labels: use cell_class for sensory/effector, cell_type for others\n",
    "def create_label(neuron_id, flow):\n",
    "    \"\"\"Vectorized label creation function\"\"\"  \n",
    "    if pd.isna(neuron_id) or pd.isna(flow):\n",
    "        return None\n",
    "    if flow in ['afferent', 'efferent']:\n",
    "        return id_to_class.get(neuron_id, id_to_type.get(neuron_id))\n",
    "    else:\n",
    "        return id_to_type.get(neuron_id)\n",
    "\n",
    "# Apply vectorized (much faster than row-wise apply)\n",
    "import numpy as np\n",
    "edgelist['pre_label'] = np.vectorize(create_label)(edgelist['pre'].values, edgelist['pre_flow'].values)\n",
    "edgelist['post_label'] = np.vectorize(create_label)(edgelist['post'].values, edgelist['post_flow'].values)\n",
    "\n",
    "# Filter out rows with missing labels\n",
    "edgelist_mixed = edgelist[edgelist['pre_label'].notna() & edgelist['post_label'].notna()].copy()\n",
    "\n",
    "print(f\"âœ“ Created mixed labels edgelist with {len(edgelist_mixed):,} connections\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensory Neuron Outputs\n",
    "\n",
    "Which cell types receive strong input from sensory neurons (â‰¥100 synapses)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T19:33:14.892083Z",
     "iopub.status.busy": "2025-12-29T19:33:14.891962Z",
     "iopub.status.idle": "2025-12-29T19:33:15.746495Z",
     "shell.execute_reply": "2025-12-29T19:33:15.745892Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate total inputs per target from sensory neurons\n",
    "sensory_post_totals = edgelist_mixed[edgelist_mixed['pre_flow'] == 'afferent'].groupby('post_label')['count'].sum()\n",
    "\n",
    "# Get sensory outputs (â‰¥100 synapses)\n",
    "sensory_outputs = edgelist_mixed[edgelist_mixed['pre_flow'] == 'afferent'].groupby(\n",
    "    ['pre_label', 'post_label']\n",
    ")['count'].sum().reset_index()\n",
    "sensory_outputs.columns = ['pre_label', 'post_label', 'total_count']\n",
    "\n",
    "# Add total counts and normalize\n",
    "sensory_outputs = sensory_outputs.merge(\n",
    "    sensory_post_totals.rename('post_total_count'),\n",
    "    left_on='post_label',\n",
    "    right_index=True\n",
    ")\n",
    "sensory_outputs['norm'] = sensory_outputs['total_count'] / sensory_outputs['post_total_count']\n",
    "\n",
    "# Filter to â‰¥100 synapses\n",
    "sensory_outputs = sensory_outputs[sensory_outputs['total_count'] >= 100]\n",
    "\n",
    "if len(sensory_outputs) > 0:\n",
    "    print(f\"Found {len(sensory_outputs)} sensory connections â‰¥100 synapses\")\n",
    "    print(f\"Sensory neuron types: {sensory_outputs['pre_label'].nunique()}\")\n",
    "    print(f\"Target neuron types: {sensory_outputs['post_label'].nunique()}\")\n",
    "    \n",
    "    # Create matrix for heatmap\n",
    "    sensory_matrix = sensory_outputs.pivot(\n",
    "        index='pre_label',\n",
    "        columns='post_label',\n",
    "        values='norm'\n",
    "    ).fillna(0)\n",
    "    \n",
    "    print(f\"Matrix dimensions: {sensory_matrix.shape[0]} x {sensory_matrix.shape[1]}\")\n",
    "    \n",
    "    # Perform hierarchical clustering for ordering\n",
    "    from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "    from scipy.spatial.distance import pdist\n",
    "    \n",
    "    # Cluster rows and columns\n",
    "    if sensory_matrix.shape[0] > 1:\n",
    "        row_linkage = linkage(pdist(sensory_matrix.values, metric='euclidean'), method='ward')\n",
    "        row_order = dendrogram(row_linkage, no_plot=True)['leaves']\n",
    "    else:\n",
    "        row_order = [0]\n",
    "    \n",
    "    if sensory_matrix.shape[1] > 1:\n",
    "        col_linkage = linkage(pdist(sensory_matrix.T.values, metric='euclidean'), method='ward')\n",
    "        col_order = dendrogram(col_linkage, no_plot=True)['leaves']\n",
    "    else:\n",
    "        col_order = [0]\n",
    "    \n",
    "    # Reorder matrix\n",
    "    sensory_matrix_ordered = sensory_matrix.iloc[row_order, col_order]\n",
    "    \n",
    "    # Create static heatmap with matplotlib/seaborn\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    sns.heatmap(\n",
    "        sensory_matrix_ordered,\n",
    "        cmap='RdYlBu_r',  # Cold to hot\n",
    "        xticklabels=False,\n",
    "        yticklabels=False,\n",
    "        cbar_kws={'label': 'Normalized Weight'},\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title('Sensory Neuron Outputs (â‰¥100 synapses)', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Target Neuron Type', fontsize=12)\n",
    "    ax.set_ylabel('Sensory Neuron Type', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{IMG_DIR}/{DATASET}_sensory_outputs.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"\\u2713 Saved static heatmap: {IMG_DIR}/{DATASET}_sensory_outputs.png\")\n",
    "    \n",
    "    # Create interactive heatmap with plotly\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=sensory_matrix_ordered.values,\n",
    "        x=sensory_matrix_ordered.columns,\n",
    "        y=sensory_matrix_ordered.index,\n",
    "        colorscale='Viridis',\n",
    "        colorbar=dict(title='Normalized<br>Weight'),\n",
    "        hovertemplate='Sensory: %{y}<br>Target: %{x}<br>Weight: %{z:.3f}<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Sensory Neuron Outputs (â‰¥100 synapses)',\n",
    "        xaxis_title='Target Neuron Type',\n",
    "        yaxis_title='Sensory Neuron Type',\n",
    "        xaxis=dict(showticklabels=False),\n",
    "        yaxis=dict(showticklabels=False),\n",
    "        height=800,\n",
    "        width=900,\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    print(f\"\\u2713 Displayed interactive heatmap\")\n",
    "else:\n",
    "    print(\"No sensory neurons with â‰¥100 synapses found in this dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effector Neuron Inputs\n",
    "\n",
    "Which cell types provide strong input to effector neurons (â‰¥100 synapses)?\n",
    "\n",
    "We'll use signed weights here to show excitatory (+) vs inhibitory (-) connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T19:33:15.748797Z",
     "iopub.status.busy": "2025-12-29T19:33:15.748659Z",
     "iopub.status.idle": "2025-12-29T19:33:15.952012Z",
     "shell.execute_reply": "2025-12-29T19:33:15.951270Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate total inputs per effector neuron type\n",
    "effector_post_totals = edgelist_mixed[edgelist_mixed['post_flow'] == 'efferent'].groupby('post_label')['count'].sum()\n",
    "\n",
    "# Get effector inputs (â‰¥100 synapses) with signed weights\n",
    "effector_inputs = edgelist_mixed[edgelist_mixed['post_flow'] == 'efferent'].groupby(\n",
    "    ['pre_label', 'post_label']\n",
    ").agg({\n",
    "    'count': 'sum',\n",
    "    'weight_signed': 'sum'\n",
    "}).reset_index()\n",
    "effector_inputs.columns = ['pre_label', 'post_label', 'total_count', 'total_signed_count']\n",
    "\n",
    "# Add total counts and normalize (signed)\n",
    "effector_inputs = effector_inputs.merge(\n",
    "    effector_post_totals.rename('post_total_count'),\n",
    "    left_on='post_label',\n",
    "    right_index=True\n",
    ")\n",
    "effector_inputs['signed_norm'] = effector_inputs['total_signed_count'] / effector_inputs['post_total_count']\n",
    "\n",
    "# Filter to â‰¥100 synapses\n",
    "effector_inputs = effector_inputs[effector_inputs['total_count'] >= 100]\n",
    "\n",
    "if len(effector_inputs) > 0:\n",
    "    print(f\"Found {len(effector_inputs)} effector input connections â‰¥100 synapses\")\n",
    "    print(f\"Input neuron types: {effector_inputs['pre_label'].nunique()}\")\n",
    "    print(f\"Effector neuron types: {effector_inputs['post_label'].nunique()}\")\n",
    "    \n",
    "    # Create matrix for heatmap\n",
    "    effector_matrix = effector_inputs.pivot(\n",
    "        index='pre_label',\n",
    "        columns='post_label',\n",
    "        values='signed_norm'\n",
    "    ).fillna(0)\n",
    "    \n",
    "    print(f\"Matrix dimensions: {effector_matrix.shape[0]} x {effector_matrix.shape[1]}\")\n",
    "    \n",
    "    # Perform hierarchical clustering on absolute values for ordering\n",
    "    if effector_matrix.shape[0] > 1:\n",
    "        row_linkage = linkage(pdist(np.abs(effector_matrix.values), metric='euclidean'), method='ward')\n",
    "        row_order = dendrogram(row_linkage, no_plot=True)['leaves']\n",
    "    else:\n",
    "        row_order = [0]\n",
    "    \n",
    "    if effector_matrix.shape[1] > 1:\n",
    "        col_linkage = linkage(pdist(np.abs(effector_matrix.T.values), metric='euclidean'), method='ward')\n",
    "        col_order = dendrogram(col_linkage, no_plot=True)['leaves']\n",
    "    else:\n",
    "        col_order = [0]\n",
    "    \n",
    "    # Reorder matrix\n",
    "    effector_matrix_ordered = effector_matrix.iloc[row_order, col_order]\n",
    "    \n",
    "    # Cap color scale at 95th percentile for better visibility\n",
    "    # Separate percentiles for positive and negative values to handle asymmetry\n",
    "    positive_vals = effector_matrix_ordered.values[effector_matrix_ordered.values > 0]\n",
    "    negative_vals = effector_matrix_ordered.values[effector_matrix_ordered.values < 0]\n",
    "    \n",
    "    if len(positive_vals) > 0:\n",
    "        p95_pos = np.percentile(positive_vals, 95)\n",
    "    else:\n",
    "        p95_pos = 0\n",
    "    \n",
    "    if len(negative_vals) > 0:\n",
    "        p95_neg = np.percentile(np.abs(negative_vals), 95)\n",
    "    else:\n",
    "        p95_neg = 0\n",
    "    \n",
    "    # Use maximum of 95th percentiles for symmetric color scale\n",
    "    max_abs_val = max(p95_pos, p95_neg)\n",
    "    \n",
    "    print(f\"Color scale range: [{-max_abs_val:.4f}, {max_abs_val:.4f}]\")\n",
    "    \n",
    "    # Create static heatmap with matplotlib/seaborn (diverging colormap)\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    sns.heatmap(\n",
    "        effector_matrix_ordered,\n",
    "        cmap='RdBu_r',  # Diverging: red (positive/excitatory) to blue (negative/inhibitory)\n",
    "        center=0,\n",
    "        vmin=-max_abs_val,\n",
    "        vmax=max_abs_val,\n",
    "        xticklabels=False,\n",
    "        yticklabels=False,\n",
    "        cbar_kws={'label': 'Signed Weight'},\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title('Signed Effector Neuron Inputs (â‰¥100 synapses)', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Effector Neuron Type', fontsize=12)\n",
    "    ax.set_ylabel('Input Neuron Type', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{IMG_DIR}/{DATASET}_effector_inputs.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"\\u2713 Saved static heatmap: {IMG_DIR}/{DATASET}_effector_inputs.png\")\n",
    "    \n",
    "    # Create interactive heatmap with plotly (red-white-blue diverging colormap)\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=effector_matrix_ordered.values,\n",
    "        x=effector_matrix_ordered.columns,\n",
    "        y=effector_matrix_ordered.index,\n",
    "        colorscale='RdBu',  # Red (positive) - White (0) - Blue (negative)\n",
    "        zmid=0,  # Center white at zero\n",
    "        zmin=-max_abs_val,\n",
    "        zmax=max_abs_val,\n",
    "        colorbar=dict(title='Signed<br>Weight'),\n",
    "        hovertemplate='Input: %{y}<br>Effector: %{x}<br>Weight: %{z:.3f}<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Signed Effector Neuron Inputs (â‰¥100 synapses)',\n",
    "        xaxis_title='Effector Neuron Type',\n",
    "        yaxis_title='Input Neuron Type',\n",
    "        xaxis=dict(showticklabels=False),\n",
    "        yaxis=dict(showticklabels=False),\n",
    "        height=800,\n",
    "        width=900,\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    print(f\"\\u2713 Displayed interactive heatmap\")\n",
    "else:\n",
    "    print(\"No effector neurons with â‰¥100 input synapses found in this dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Turn: New Subset\n",
    "\n",
    "Now try this analysis yourself with a different dataset!\n",
    "\n",
    "**Exercise:** Switch the pre-prepared subset at the top of the notebook:\n",
    "- Try `antennal_lobe` to explore olfactory circuits\n",
    "- Try `front_leg` to examine leg sensorimotor circuits\n",
    "- Try `mushroom_body` for learning and memory circuits\n",
    "\n",
    "Simply change the `SUBSET_NAME` variable in the configuration cell and re-run the notebook!\n",
    "\n",
    "---\n",
    "\n",
    "# Extensions\n",
    "\n",
    "In the extended code blocks below, you can learn how to identify connectivity-based clusters and visualise cluster morphologies. These analyses involve longer compute times but reveal functional groupings based on connectivity patterns.\n",
    "\n",
    "## UMAP Dimensionality Reduction\n",
    "\n",
    "Use UMAP to visualize connectivity patterns in 2D space based on cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T19:33:15.954738Z",
     "iopub.status.busy": "2025-12-29T19:33:15.954620Z",
     "iopub.status.idle": "2025-12-29T19:33:25.118367Z",
     "shell.execute_reply": "2025-12-29T19:33:25.117877Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter neurons with sufficient connectivity (>=10 connections)\n",
    "conn_counts = pd.concat([\n",
    "    edgelist.groupby('pre').size().rename('n_out'),\n",
    "    edgelist.groupby('post').size().rename('n_in')\n",
    "], axis=1).fillna(0)\n",
    "conn_counts['total'] = conn_counts['n_out'] + conn_counts['n_in']\n",
    "\n",
    "neurons_to_use = conn_counts[conn_counts['total'] >= 10].index.tolist()\n",
    "print(f\"Using {len(neurons_to_use):,} neurons with â‰¥10 connections\")\n",
    "\n",
    "# Create input/output connectivity matrix\n",
    "# Each neuron has both input and output partners\n",
    "edgelist_filtered = edgelist[\n",
    "    (edgelist['pre'].isin(neurons_to_use)) | \n",
    "    (edgelist['post'].isin(neurons_to_use))\n",
    "].copy()\n",
    "\n",
    "# Replace zeros with small value\n",
    "edgelist_filtered['norm'] = edgelist_filtered['norm'].replace(0, 0.001)\n",
    "\n",
    "# Prepare connectivity data (inputs and outputs as separate features)\n",
    "conn_list = []\n",
    "\n",
    "# Outputs: neuron -> partner\n",
    "outputs = edgelist_filtered[edgelist_filtered['pre'].isin(neurons_to_use)][['pre', 'post', 'norm']].copy()\n",
    "outputs.columns = ['neuron', 'partner', 'weight']\n",
    "outputs['partner'] = 'output_' + outputs['partner']\n",
    "conn_list.append(outputs)\n",
    "\n",
    "# Inputs: partner -> neuron\n",
    "inputs = edgelist_filtered[edgelist_filtered['post'].isin(neurons_to_use)][['post', 'pre', 'norm']].copy()\n",
    "inputs.columns = ['neuron', 'partner', 'weight']\n",
    "inputs['partner'] = 'input_' + inputs['partner']\n",
    "conn_list.append(inputs)\n",
    "\n",
    "# Combine\n",
    "conn_data = pd.concat(conn_list, ignore_index=True)\n",
    "\n",
    "# Create sparse matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Create indices\n",
    "neuron_idx = {n: i for i, n in enumerate(neurons_to_use)}\n",
    "partner_idx = {p: i for i, p in enumerate(conn_data['partner'].unique())}\n",
    "\n",
    "rows = conn_data['neuron'].map(neuron_idx).values\n",
    "cols = conn_data['partner'].map(partner_idx).values\n",
    "data = conn_data['weight'].values\n",
    "\n",
    "connectivity_matrix = csr_matrix(\n",
    "    (data, (rows, cols)),\n",
    "    shape=(len(neurons_to_use), len(partner_idx))\n",
    ")\n",
    "\n",
    "print(f\"Connectivity matrix: {connectivity_matrix.shape}\")\n",
    "print(f\"Sparsity: {100 * (1 - connectivity_matrix.nnz / (connectivity_matrix.shape[0] * connectivity_matrix.shape[1])):.2f}%\")\n",
    "\n",
    "# Calculate cosine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity_matrix = cosine_similarity(connectivity_matrix)\n",
    "similarity_matrix[np.isnan(similarity_matrix)] = 0\n",
    "similarity_matrix[np.isinf(similarity_matrix)] = 0\n",
    "\n",
    "print(f\"âœ“ Similarity matrix: {similarity_matrix.shape}\")\n",
    "\n",
    "# Convert to distance for UMAP\n",
    "distance_matrix = 1 - similarity_matrix\n",
    "distance_matrix = np.clip(distance_matrix, 0, 2)  # Ensure valid distances\n",
    "\n",
    "# Run UMAP\n",
    "reducer = umap.UMAP(\n",
    "    n_neighbors=15,\n",
    "    min_dist=0.1,\n",
    "    n_components=2,\n",
    "    metric='precomputed',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "umap_embedding = reducer.fit_transform(distance_matrix)\n",
    "print(f\"âœ“ UMAP complete\")\n",
    "\n",
    "# Create DataFrame with UMAP coordinates and metadata\n",
    "umap_df = pd.DataFrame({\n",
    "    'neuron_id': neurons_to_use,\n",
    "    'UMAP1': umap_embedding[:, 0],\n",
    "    'UMAP2': umap_embedding[:, 1]\n",
    "})\n",
    "\n",
    "# Add metadata\n",
    "meta_subset = meta.set_index(DATASET_ID).loc[neurons_to_use]\n",
    "umap_df = umap_df.merge(\n",
    "    meta_subset[['cell_type', 'super_class', 'cell_class', 'flow']].reset_index(),\n",
    "    left_on='neuron_id',\n",
    "    right_on=DATASET_ID,\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Created UMAP DataFrame with {len(umap_df):,} neurons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize UMAP by Super Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T19:33:25.120106Z",
     "iopub.status.busy": "2025-12-29T19:33:25.119982Z",
     "iopub.status.idle": "2025-12-29T19:33:25.183662Z",
     "shell.execute_reply": "2025-12-29T19:33:25.183166Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot UMAP colored by super_class\n",
    "fig = px.scatter(\n",
    "    umap_df,\n",
    "    x='UMAP1',\n",
    "    y='UMAP2',\n",
    "    color='super_class',\n",
    "    hover_data=['neuron_id', 'cell_type'],\n",
    "    title='UMAP of Connectivity Patterns<br><sub>Colored by Super Class</sub>',\n",
    "    template='plotly_white',\n",
    "    height=600,\n",
    "    width=800\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=4, opacity=0.6))\n",
    "fig.write_html(f\"{IMG_DIR}/{DATASET}_umap_super_class.html\")\n",
    "fig.show()\n",
    "\n",
    "print(f\"âœ“ Saved UMAP super_class plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connectivity Clusters\n",
    "\n",
    "There are many ways to cluster nodes by connectivity. Here we use a simple but effective method: hierarchical clustering based on connectivity similarity.\n",
    "\n",
    "### Hierarchical Clustering\n",
    "\n",
    "Cluster neurons based on their connectivity patterns using Ward's method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T19:33:25.192642Z",
     "iopub.status.busy": "2025-12-29T19:33:25.192513Z",
     "iopub.status.idle": "2025-12-29T19:33:25.437156Z",
     "shell.execute_reply": "2025-12-29T19:33:25.436588Z"
    }
   },
   "outputs": [],
   "source": [
    "# Perform hierarchical clustering\n",
    "\n",
    "# Use distance matrix\n",
    "condensed_distance = squareform(distance_matrix, checks=False)\n",
    "\n",
    "# Hierarchical clustering\n",
    "linkage_matrix = linkage(condensed_distance, method='ward')\n",
    "\n",
    "# Cut tree to get clusters (e.g., 12 clusters)\n",
    "n_clusters = 12\n",
    "clusters = cut_tree(linkage_matrix, n_clusters=n_clusters).flatten()\n",
    "\n",
    "umap_df['cluster'] = clusters + 1  # 1-indexed for readability\n",
    "\n",
    "print(f\"âœ“ Created {n_clusters} clusters\")\n",
    "print(f\"\\nCluster sizes:\")\n",
    "print(umap_df['cluster'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize UMAP by Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T19:33:25.439066Z",
     "iopub.status.busy": "2025-12-29T19:33:25.438936Z",
     "iopub.status.idle": "2025-12-29T19:33:25.510710Z",
     "shell.execute_reply": "2025-12-29T19:33:25.510093Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate cluster centroids for labeling\n",
    "cluster_centroids = umap_df.groupby('cluster').agg({\n",
    "    'UMAP1': 'mean',\n",
    "    'UMAP2': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Create color palette\n",
    "import plotly.colors as pc\n",
    "cluster_colors = pc.sample_colorscale('Viridis', [i/(n_clusters-1) for i in range(n_clusters)])\n",
    "\n",
    "# Plot UMAP colored by cluster\n",
    "fig = px.scatter(\n",
    "    umap_df,\n",
    "    x='UMAP1',\n",
    "    y='UMAP2',\n",
    "    color='cluster',\n",
    "    hover_data=['neuron_id', 'cell_type'],\n",
    "    title=f'Connectivity-Based Clusters<br><sub>{n_clusters} clusters identified by hierarchical clustering</sub>',\n",
    "    template='plotly_white',\n",
    "    height=600,\n",
    "    width=800,\n",
    "    color_continuous_scale='Viridis'\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=5, opacity=0.7))\n",
    "\n",
    "# Add cluster labels\n",
    "for _, row in cluster_centroids.iterrows():\n",
    "    fig.add_annotation(\n",
    "        x=row['UMAP1'],\n",
    "        y=row['UMAP2'],\n",
    "        text=str(int(row['cluster'])),\n",
    "        showarrow=False,\n",
    "        font=dict(size=14, color='black'),\n",
    "        bgcolor='white',\n",
    "        opacity=0.8\n",
    "    )\n",
    "\n",
    "fig.write_html(f\"{IMG_DIR}/{DATASET}_umap_clusters.html\")\n",
    "fig.show()\n",
    "\n",
    "print(f\"âœ“ Saved UMAP clusters plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Composition Analysis\n",
    "\n",
    "Examine what cell types are present in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T19:33:25.518299Z",
     "iopub.status.busy": "2025-12-29T19:33:25.518168Z",
     "iopub.status.idle": "2025-12-29T19:33:25.704675Z",
     "shell.execute_reply": "2025-12-29T19:33:25.704266Z"
    }
   },
   "outputs": [],
   "source": [
    "# Count super_classes within each cluster\n",
    "cluster_composition = umap_df.groupby(['cluster', 'super_class']).size().reset_index(name='count')\n",
    "\n",
    "# Get top 5 super_classes per cluster\n",
    "top_per_cluster = cluster_composition.sort_values(['cluster', 'count'], ascending=[True, False])\n",
    "top_per_cluster = top_per_cluster.groupby('cluster').head(5)\n",
    "\n",
    "# Create stacked bar chart\n",
    "fig = px.bar(\n",
    "    top_per_cluster,\n",
    "    x='cluster',\n",
    "    y='count',\n",
    "    color='super_class',\n",
    "    title='Cluster Composition by Super Class<br><sub>Top 5 super classes per cluster</sub>',\n",
    "    labels={'cluster': 'Cluster', 'count': 'Number of Neurons'},\n",
    "    template='plotly_white',\n",
    "    height=500,\n",
    "    width=900\n",
    ")\n",
    "\n",
    "fig.write_html(f\"{IMG_DIR}/{DATASET}_cluster_composition.html\")\n",
    "fig.show()\n",
    "\n",
    "print(f\"âœ“ Saved cluster composition plot\")\n",
    "\n",
    "# Print detailed composition for first 3 clusters\n",
    "print(\"\\nDetailed composition for clusters 1-3:\")\n",
    "for cluster_id in range(1, 4):\n",
    "    cluster_data = cluster_composition[cluster_composition['cluster'] == cluster_id].sort_values('count', ascending=False)\n",
    "    print(f\"\\nCluster {cluster_id}:\")\n",
    "    print(cluster_data.head(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensory and Effector Neurons\n",
    "\n",
    "Highlight sensory (afferent) and effector (efferent) neurons in the UMAP space to understand their distribution across connectivity clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T19:33:25.706567Z",
     "iopub.status.busy": "2025-12-29T19:33:25.706451Z",
     "iopub.status.idle": "2025-12-29T19:33:25.743698Z",
     "shell.execute_reply": "2025-12-29T19:33:25.743085Z"
    }
   },
   "outputs": [],
   "source": [
    "# Identify sensory and effector neurons\n",
    "umap_df['is_sensory'] = umap_df['flow'] == 'afferent'\n",
    "umap_df['is_effector'] = umap_df['flow'] == 'efferent'\n",
    "\n",
    "# Create display categories\n",
    "umap_df['neuron_type'] = 'Other'\n",
    "umap_df.loc[umap_df['is_sensory'], 'neuron_type'] = 'Sensory (afferent)'\n",
    "umap_df.loc[umap_df['is_effector'], 'neuron_type'] = 'Effector (efferent)'\n",
    "\n",
    "# Create plot with three layers\n",
    "fig = go.Figure()\n",
    "\n",
    "# Plot \"Other\" neurons first (grey, low opacity)\n",
    "other_df = umap_df[umap_df['neuron_type'] == 'Other']\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=other_df['UMAP1'],\n",
    "    y=other_df['UMAP2'],\n",
    "    mode='markers',\n",
    "    name='Other',\n",
    "    marker=dict(color='grey', size=4, opacity=0.3),\n",
    "    hovertext=other_df['cell_type'],\n",
    "    hoverinfo='text'\n",
    "))\n",
    "\n",
    "# Plot sensory neurons (circles)\n",
    "sensory_df = umap_df[umap_df['is_sensory']]\n",
    "if len(sensory_df) > 0:\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=sensory_df['UMAP1'],\n",
    "        y=sensory_df['UMAP2'],\n",
    "        mode='markers',\n",
    "        name='Sensory (afferent)',\n",
    "        marker=dict(color='red', size=6, opacity=0.8, symbol='circle'),\n",
    "        hovertext=sensory_df['cell_type'],\n",
    "        hoverinfo='text'\n",
    "    ))\n",
    "\n",
    "# Plot effector neurons (squares)\n",
    "effector_df = umap_df[umap_df['is_effector']]\n",
    "if len(effector_df) > 0:\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=effector_df['UMAP1'],\n",
    "        y=effector_df['UMAP2'],\n",
    "        mode='markers',\n",
    "        name='Effector (efferent)',\n",
    "        marker=dict(color='blue', size=6, opacity=0.8, symbol='square'),\n",
    "        hovertext=effector_df['cell_type'],\n",
    "        hoverinfo='text'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='UMAP: Sensory and Effector Neurons<br><sub>Sensory = red circles, Effector = blue squares</sub>',\n",
    "    xaxis_title='UMAP1',\n",
    "    yaxis_title='UMAP2',\n",
    "    template='plotly_white',\n",
    "    height=600,\n",
    "    width=800\n",
    ")\n",
    "\n",
    "fig.write_html(f\"{IMG_DIR}/{DATASET}_umap_sensory_effector.html\")\n",
    "fig.show()\n",
    "\n",
    "print(f\"âœ“ Saved sensory/effector UMAP plot\")\n",
    "print(f\"Sensory neurons: {umap_df['is_sensory'].sum():,}\")\n",
    "print(f\"Effector neurons: {umap_df['is_effector'].sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we covered comprehensive connectivity analysis methods for the BANC dataset:\n",
    "\n",
    "### Core Analyses\n",
    "\n",
    "1. **Loading connectivity data** - Working with edgelists and meta data\n",
    "2. **Neurotransmitter prediction** - Classifying connections as excitatory/inhibitory\n",
    "3. **Basic network statistics** - Degree distributions, weight correlations\n",
    "4. **Network visualization** - Graph plots by super_class\n",
    "5. **Connectivity matrices** - Heatmaps of cell type connectivity\n",
    "6. **Sensory-effector analysis** - Interpretable input-output patterns\n",
    "\n",
    "### Extended Analyses\n",
    "\n",
    "7. **UMAP dimensionality reduction** - Projecting connectivity patterns into 2D space\n",
    "8. **Hierarchical clustering** - Grouping neurons by connectivity similarity\n",
    "9. **Cluster composition** - Understanding what cell types form each cluster\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Edgelists** describe directed, weighted graphs of neural connectivity\n",
    "- **Signed connectivity** provides insights into excitatory/inhibitory balance, but should be interpreted cautiously\n",
    "- **Cosine similarity** is effective for comparing connectivity patterns\n",
    "- **UMAP** reveals hidden structure in high-dimensional connectivity data\n",
    "- **Sensory and effector neurons** provide interpretable anchors for circuit analysis\n",
    "- **Hierarchical clustering** can identify functional groups based purely on connectivity\n",
    "\n",
    "### Files Generated\n",
    "\n",
    "All plots have been saved to `images/tutorial_03/` as interactive HTML and static PNG files for publication.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Compare connectivity patterns across different datasets (FAFB, MANC, hemibrain)\n",
    "- Analyze specific pathways or circuits of interest\n",
    "- Investigate connection specificity and network motifs\n",
    "- Combine morphological and connectivity features for multimodal analysis\n",
    "\n",
    "---\n",
    "\n",
    "**Tutorial Complete!** \n",
    "\n",
    "You now have a comprehensive pipeline for analyzing fly connectome connectivity data in Python."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
